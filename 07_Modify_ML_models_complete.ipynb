{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williamtbarker/ML4Molecules/blob/main/07_Modify_ML_models_complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating custom ML models\n",
        "\n",
        "So far we have used ML models available in the python packages. Here, we will look into the code for the models and see how we can tweek it to make new ML models.\n",
        "\n",
        "We will use the MPNN model from `dgl` and make changes to the model. We will test those models on a subset of the QM9 dataset as before.\n",
        "\n"
      ],
      "metadata": {
        "id": "4vvbsbiaBPpY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing packages and creating the dataloader"
      ],
      "metadata": {
        "id": "W242HZqnCSgW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hnb5DmnnBAui",
        "outputId": "968a3992-9346-4104-c584-4ff492e8ca42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.3-cp310-cp310-manylinux1_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.3\n",
            "Collecting dgllife\n",
            "  Downloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgllife) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgllife) (3.2.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from dgllife) (0.2.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.16.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2023.3.post1)\n",
            "Installing collected packages: dgllife\n",
            "Successfully installed dgllife-0.3.2\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.4\n",
            "Collecting fast_ml\n",
            "  Downloading fast_ml-3.68-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fast_ml\n",
            "Successfully installed fast_ml-3.68\n"
          ]
        }
      ],
      "source": [
        "# install dgl, rdkit and fast-ml\n",
        "! pip install dgl\n",
        "! pip install dgllife\n",
        "! pip install rdkit\n",
        "! pip install fast_ml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# load the dataframe as CSV from URL.\n",
        "df = pd.read_csv(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\")\n",
        "\n",
        "# create the dataset with smiles and gap\n",
        "# we will use a 5% of the dataset to save time\n",
        "dataset = df[[\"smiles\",\"gap\"]].sample(frac=0.05)\n",
        "\n",
        "# import from rdkit and dgl-lifesci\n",
        "from rdkit import Chem\n",
        "from dgllife.utils import CanonicalAtomFeaturizer, CanonicalBondFeaturizer, \\\n",
        "mol_to_bigraph\n",
        "\n",
        "# create the atom and bond featurizer object\n",
        "atom_featurizer = CanonicalAtomFeaturizer(atom_data_field=\"hv\")\n",
        "bond_featurizer = CanonicalBondFeaturizer(bond_data_field=\"he\")\n",
        "\n",
        "# helper function to convert smiles to graph\n",
        "def smiles2graph(smiles):\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "  graph = mol_to_bigraph(mol, node_featurizer=atom_featurizer,\n",
        "                     edge_featurizer=bond_featurizer)\n",
        "  return graph\n",
        "\n",
        "dataset[\"graph\"] = dataset[\"smiles\"].apply(smiles2graph)\n",
        "\n",
        "\n",
        "# import the function to split into train-valid-test\n",
        "from fast_ml.model_development import train_valid_test_split\n",
        "\n",
        "X_train, y_train, X_valid, y_valid, \\\n",
        "X_test, y_test = train_valid_test_split(dataset[[\"graph\",\"gap\"]],\n",
        "                                        target = \"gap\",\n",
        "                                        train_size=0.8,\n",
        "                                        valid_size=0.1,\n",
        "                                        test_size=0.1)\n",
        "\n",
        "# Creating dataloader\n",
        "import dgl\n",
        "\n",
        "def collate_data(data):\n",
        "  # our data is in the form of list of (X,y)\n",
        "  # the map function thus maps accordingly\n",
        "  graphs, y = map(list, zip(*data))\n",
        "\n",
        "  # for creating a batch of graph, we use the batch function\n",
        "  batch_graph = dgl.batch(graphs)\n",
        "\n",
        "  # we need to stack the ys for different entries in the batch\n",
        "  y = torch.stack(y, dim=0)\n",
        "\n",
        "  return batch_graph, y\n",
        "\n",
        "# import dataloader\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# create the dataloader for train dataset\n",
        "# dataset should be of form (X,y) according to the collate function\n",
        "# the ys should also be converted to tensors\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=list(zip(X_train[\"graph\"].values.tolist(),\n",
        "                     torch.tensor(y_train.tolist(), dtype=torch.float32))),\n",
        "    batch_size=64, collate_fn=collate_data)\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset=list(zip(X_valid[\"graph\"].values.tolist(),\n",
        "                     torch.tensor(y_valid.tolist(), dtype=torch.float32))),\n",
        "    batch_size=64, collate_fn=collate_data)\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=list(zip(X_test[\"graph\"].values.tolist(),\n",
        "                     torch.tensor(y_test.tolist(), dtype=torch.float32))),\n",
        "    batch_size=64, collate_fn=collate_data)\n",
        "\n",
        "# loss function for regresssion is usually mean squared error\n",
        "import torch\n",
        "\n",
        "loss_func = torch.nn.MSELoss(reduce=None)"
      ],
      "metadata": {
        "id": "_pIdh3HYCawB",
        "outputId": "2573ec7e-cbf1-4296-9d6c-fd554c0b3675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to train and validate the model"
      ],
      "metadata": {
        "id": "OgYfBiefDTE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_train_valid(model, optimizer, loss_func,\n",
        "                    train_dataloader, valid_dataloader):\n",
        "\n",
        "      epochs = 1\n",
        "\n",
        "      # loop over epochs\n",
        "      for epoch in range(epochs):\n",
        "        print(\"\\nStarting Epoch\", epoch+1)\n",
        "\n",
        "        # set the model to train so the parameters can be updated\n",
        "        model.train()\n",
        "        # loop over training batches\n",
        "\n",
        "        train_loss = []\n",
        "        for batch in train_dataloader:\n",
        "\n",
        "          # Do a forward pass\n",
        "          batch_graph, target = batch\n",
        "\n",
        "          # look at the forward function for input\n",
        "          # this model needs graph, node_feats and edge_feats\n",
        "          node_feats = batch_graph.ndata[\"hv\"]\n",
        "          edge_feats = batch_graph.edata[\"he\"]\n",
        "          predictions = model(batch_graph, node_feats, edge_feats)\n",
        "\n",
        "          # Compute loss\n",
        "          loss = (loss_func(predictions, target)).mean()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Do back propogation and update gradient\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # save loss to compute average loss\n",
        "          train_loss.append(loss)\n",
        "\n",
        "        print(\"Training loss\", torch.tensor(train_loss).mean().item())\n",
        "\n",
        "\n",
        "\n",
        "        # set the model to eval so the parameters are not updated\n",
        "        model.eval()\n",
        "        valid_loss = []\n",
        "\n",
        "        # loop over validation batches\n",
        "        with torch.no_grad():\n",
        "          for batch in valid_dataloader:\n",
        "\n",
        "            # Do a forward pass\n",
        "            batch_graph, target = batch\n",
        "            node_feats = batch_graph.ndata[\"hv\"]\n",
        "            edge_feats = batch_graph.edata[\"he\"]\n",
        "            predictions = model(batch_graph, node_feats, edge_feats)\n",
        "\n",
        "            # Compute loss and gradient\n",
        "            loss = (loss_func(predictions, target)).mean()\n",
        "\n",
        "            # save loss to compute average loss\n",
        "            valid_loss.append(loss)\n",
        "\n",
        "        print(\"Validation loss\", torch.tensor(valid_loss).mean().item())\n"
      ],
      "metadata": {
        "id": "KqpMLMQIC4Gw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the default MPNN model"
      ],
      "metadata": {
        "id": "7l3g-AmSDtHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import MLP model from dgl-lifesci\n",
        "from dgllife.model.model_zoo.mpnn_predictor import MPNNPredictor\n",
        "\n",
        "# the atom feature length is 74 and bond is 12\n",
        "model = MPNNPredictor(node_in_feats = 74,\n",
        "                      edge_in_feats = 12,\n",
        "                      node_out_feats = 64,\n",
        "                      edge_hidden_feats = 128,\n",
        "                      n_tasks = 1,\n",
        "                      num_step_message_passing = 6,\n",
        "                      num_step_set2set = 6,\n",
        "                      num_layer_set2set = 3)\n",
        "\n",
        "# adam optimier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "run_train_valid(model=model, loss_func=loss_func,\n",
        "                optimizer=optimizer, train_dataloader=train_dataloader,\n",
        "                valid_dataloader=valid_dataloader)"
      ],
      "metadata": {
        "id": "IncsXBnbDyl5",
        "outputId": "eb9871d1-8f25-4aa9-e62d-14b689c29d8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Epoch 1\n",
            "Training loss 0.0030192320700734854\n",
            "Validation loss 0.0025105439126491547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing the ML init code\n",
        "\n",
        "Below is the code for the MPNNPredictor from [dgl](https://github.com/awslabs/dgl-lifesci/blob/master/python/dgllife/model/model_zoo/mpnn_predictor.py)"
      ],
      "metadata": {
        "id": "Rg8fHWLrFjEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "import torch.nn as nn\n",
        "\n",
        "from dgl.nn.pytorch import Set2Set\n",
        "\n",
        "from dgllife.model.gnn import MPNNGNN\n",
        "\n",
        "class MPNNPredictor(nn.Module):\n",
        "    \"\"\"MPNN for regression and classification on graphs.\n",
        "\n",
        "    MPNN is introduced in `Neural Message Passing for Quantum Chemistry\n",
        "    <https://arxiv.org/abs/1704.01212>`__.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    node_in_feats : int\n",
        "        Size for the input node features.\n",
        "    edge_in_feats : int\n",
        "        Size for the input edge features.\n",
        "    node_out_feats : int\n",
        "        Size for the output node representations. Default to 64.\n",
        "    edge_hidden_feats : int\n",
        "        Size for the hidden edge representations. Default to 128.\n",
        "    n_tasks : int\n",
        "        Number of tasks, which is also the output size. Default to 1.\n",
        "    num_step_message_passing : int\n",
        "        Number of message passing steps. Default to 6.\n",
        "    num_step_set2set : int\n",
        "        Number of set2set steps. Default to 6.\n",
        "    num_layer_set2set : int\n",
        "        Number of set2set layers. Default to 3.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 node_in_feats,\n",
        "                 edge_in_feats,\n",
        "                 node_out_feats=64,\n",
        "                 edge_hidden_feats=128,\n",
        "                 n_tasks=1,\n",
        "                 num_step_message_passing=6,\n",
        "                 num_step_set2set=6,\n",
        "                 num_layer_set2set=3):\n",
        "        super(MPNNPredictor, self).__init__()\n",
        "\n",
        "        self.gnn = MPNNGNN(node_in_feats=node_in_feats,\n",
        "                           node_out_feats=node_out_feats,\n",
        "                           edge_in_feats=edge_in_feats,\n",
        "                           edge_hidden_feats=edge_hidden_feats,\n",
        "                           num_step_message_passing=num_step_message_passing)\n",
        "        self.readout = Set2Set(input_dim=node_out_feats,\n",
        "                               n_iters=num_step_set2set,\n",
        "                               n_layers=num_layer_set2set)\n",
        "        self.predict = nn.Sequential(\n",
        "            nn.Linear(2 * node_out_feats, node_out_feats),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(node_out_feats, n_tasks)\n",
        "        )\n",
        "\n",
        "    def forward(self, g, node_feats, edge_feats):\n",
        "        \"\"\"Graph-level regression/soft classification.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        g : DGLGraph\n",
        "            DGLGraph for a batch of graphs.\n",
        "        node_feats : float32 tensor of shape (V, node_in_feats)\n",
        "            Input node features.\n",
        "        edge_feats : float32 tensor of shape (E, edge_in_feats)\n",
        "            Input edge features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float32 tensor of shape (G, n_tasks)\n",
        "            Prediction for the graphs in the batch. G for the number of graphs.\n",
        "        \"\"\"\n",
        "        node_feats = self.gnn(g, node_feats, edge_feats)\n",
        "        graph_feats = self.readout(g, node_feats)\n",
        "        return self.predict(graph_feats)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "BE4Q6mHaE3ND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we want to add one more `Linear` layer to the *predict* with `ReLU` activation. We copy paste the entire class and make that change.\n",
        "\n",
        "We will call the model *MPNN_modified*"
      ],
      "metadata": {
        "id": "UzWvNmQNHPaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the import statements\n",
        "import torch.nn as nn\n",
        "from dgl.nn.pytorch import Set2Set\n",
        "from dgllife.model.gnn import MPNNGNN\n",
        "\n",
        "# creating the class; change the class name\n",
        "class MPNN_modified(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 node_in_feats,\n",
        "                 edge_in_feats,\n",
        "                 node_out_feats=64,\n",
        "                 edge_hidden_feats=128,\n",
        "                 n_tasks=1,\n",
        "                 num_step_message_passing=6,\n",
        "                 num_step_set2set=6,\n",
        "                 num_layer_set2set=3):\n",
        "\n",
        "        # don't forget to change the class name in super\n",
        "        super(MPNN_modified, self).__init__()\n",
        "\n",
        "        self.gnn = MPNNGNN(node_in_feats=node_in_feats,\n",
        "                           node_out_feats=node_out_feats,\n",
        "                           edge_in_feats=edge_in_feats,\n",
        "                           edge_hidden_feats=edge_hidden_feats,\n",
        "                           num_step_message_passing=num_step_message_passing)\n",
        "        self.readout = Set2Set(input_dim=node_out_feats,\n",
        "                               n_iters=num_step_set2set,\n",
        "                               n_layers=num_layer_set2set)\n",
        "        self.predict = nn.Sequential(\n",
        "            nn.Linear(2 * node_out_feats, node_out_feats),\n",
        "            nn.ReLU(),\n",
        "\n",
        "\n",
        "            #################################\n",
        "            # let's add a linear layer followed by ReLU\n",
        "            # the input size should match the output of previous layer\n",
        "            nn.Linear(node_out_feats, 2 * node_out_feats),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            ######################################\n",
        "            nn.Linear(2 * node_out_feats, n_tasks)\n",
        "        )\n",
        "\n",
        "    # No change here as we did not change the gnn, readout or predict inputs\n",
        "    def forward(self, g, node_feats, edge_feats):\n",
        "\n",
        "        node_feats = self.gnn(g, node_feats, edge_feats)\n",
        "        graph_feats = self.readout(g, node_feats)\n",
        "        return self.predict(graph_feats)"
      ],
      "metadata": {
        "id": "YbDMUE4PEIdY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can train this ML model. The model parameters have not changed. So, we can use the same parameters as before."
      ],
      "metadata": {
        "id": "Lorxp29rJpBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the atom feature length is 74 and bond is 12\n",
        "model = MPNN_modified(node_in_feats = 74,\n",
        "                      edge_in_feats = 12,\n",
        "                      node_out_feats = 64,\n",
        "                      edge_hidden_feats = 128,\n",
        "                      n_tasks = 1,\n",
        "                      num_step_message_passing = 6,\n",
        "                      num_step_set2set = 6,\n",
        "                      num_layer_set2set = 3)\n",
        "\n",
        "# adam optimier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "run_train_valid(model=model, loss_func=loss_func,\n",
        "                optimizer=optimizer, train_dataloader=train_dataloader,\n",
        "                valid_dataloader=valid_dataloader)"
      ],
      "metadata": {
        "id": "uafT-lRgJtVu",
        "outputId": "ea1faf0b-fef6-46f5-b53d-5011ae08de76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Epoch 1\n",
            "Training loss 0.004423568490892649\n",
            "Validation loss 0.0024187173694372177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training code works! Suppose we wanted to control the number of linear layers added using a argument to the model, for example, *num_linear_layers*.\n",
        "\n",
        "We will do that in the following code"
      ],
      "metadata": {
        "id": "5_px-j-bKgAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the import statements\n",
        "import torch.nn as nn\n",
        "from dgl.nn.pytorch import Set2Set\n",
        "from dgllife.model.gnn import MPNNGNN\n",
        "\n",
        "# creating the class; change the class name\n",
        "class MPNN_modified(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 node_in_feats,\n",
        "                 edge_in_feats,\n",
        "                 node_out_feats=64,\n",
        "                 edge_hidden_feats=128,\n",
        "                 n_tasks=1,\n",
        "                 num_step_message_passing=6,\n",
        "                 num_step_set2set=6,\n",
        "                 num_layer_set2set=3,\n",
        "                 # add the num_linear_layers\n",
        "                 num_linear_layers = 1\n",
        "                 ):\n",
        "\n",
        "        # don't forget to change the class name in super\n",
        "        super(MPNN_modified, self).__init__()\n",
        "\n",
        "        self.gnn = MPNNGNN(node_in_feats=node_in_feats,\n",
        "                           node_out_feats=node_out_feats,\n",
        "                           edge_in_feats=edge_in_feats,\n",
        "                           edge_hidden_feats=edge_hidden_feats,\n",
        "                           num_step_message_passing=num_step_message_passing)\n",
        "        self.readout = Set2Set(input_dim=node_out_feats,\n",
        "                               n_iters=num_step_set2set,\n",
        "                               n_layers=num_layer_set2set)\n",
        "\n",
        "        ######################################\n",
        "        # we can use a for loop to add desired number of layers\n",
        "        layers = []\n",
        "        for i in range(num_linear_layers):\n",
        "              layers.append(nn.Linear(node_out_feats, node_out_feats))\n",
        "              layers.append(nn.ReLU())\n",
        "\n",
        "        ######################################\n",
        "\n",
        "        self.predict = nn.Sequential(\n",
        "            nn.Linear(2 * node_out_feats, node_out_feats),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            ## adding the linear layers\n",
        "            nn.Sequential(*layers),\n",
        "\n",
        "            nn.Linear(node_out_feats, n_tasks)\n",
        "        )\n",
        "\n",
        "    # No change here as we did not change the gnn, readout or predict inputs\n",
        "    def forward(self, g, node_feats, edge_feats):\n",
        "\n",
        "        node_feats = self.gnn(g, node_feats, edge_feats)\n",
        "        graph_feats = self.readout(g, node_feats)\n",
        "        return self.predict(graph_feats)"
      ],
      "metadata": {
        "id": "cAPfKsjdJ-Tt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the `model.predict` with `num_linear_layers` set to 1"
      ],
      "metadata": {
        "id": "uDbcppmqMcG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MPNN_modified(node_in_feats = 74,\n",
        "                      edge_in_feats = 12,\n",
        "                      node_out_feats = 64,\n",
        "                      edge_hidden_feats = 128,\n",
        "                      n_tasks = 1,\n",
        "                      num_step_message_passing = 6,\n",
        "                      num_step_set2set = 6,\n",
        "                      num_layer_set2set = 3,\n",
        "                      num_linear_layers=1)\n",
        "model.predict\n"
      ],
      "metadata": {
        "id": "wrr5Pp8zMdsW",
        "outputId": "5f208d1d-70f2-4430-c6f8-f04364070bf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (3): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add 3 layers and train the model"
      ],
      "metadata": {
        "id": "Mrx3wi6jNG3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MPNN_modified(node_in_feats = 74,\n",
        "                      edge_in_feats = 12,\n",
        "                      node_out_feats = 64,\n",
        "                      edge_hidden_feats = 128,\n",
        "                      n_tasks = 1,\n",
        "                      num_step_message_passing = 6,\n",
        "                      num_step_set2set = 6,\n",
        "                      num_layer_set2set = 3,\n",
        "                      num_linear_layers=3)\n",
        "model.predict\n"
      ],
      "metadata": {
        "id": "TpIUrHSKMlxl",
        "outputId": "93f36ec5-119d-4e6e-b7af-8079077e9e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "  )\n",
              "  (3): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adam optimier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "run_train_valid(model=model, loss_func=loss_func,\n",
        "                optimizer=optimizer, train_dataloader=train_dataloader,\n",
        "                valid_dataloader=valid_dataloader)"
      ],
      "metadata": {
        "id": "vy9ITZB-NN0t",
        "outputId": "8d181dd2-bdf5-4c78-ca37-06fb78749632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Epoch 1\n",
            "Training loss 0.01042400673031807\n",
            "Validation loss 0.0024073352105915546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changes to forward function\n",
        "\n",
        "In a published [article](https://pubs.acs.org/doi/10.1021/acs.jcim.9b00237) addiding fingerprints or descriptors to the output from readout layer was found to increase the prediction accuracy"
      ],
      "metadata": {
        "id": "2LWHMFUzOkWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "crvE-M44LoG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In such cases, we will need to modify the `forward` to take in the descriptors/fingerprints. Here, for sake of simplicity, we will just modify the `forward` function to multiply the output readout by a constant  "
      ],
      "metadata": {
        "id": "SiERCI31MHI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the import statements\n",
        "import torch.nn as nn\n",
        "from dgl.nn.pytorch import Set2Set\n",
        "from dgllife.model.gnn import MPNNGNN\n",
        "\n",
        "# creating the class; change the class name\n",
        "class MPNN_modified(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 node_in_feats,\n",
        "                 edge_in_feats,\n",
        "                 node_out_feats=64,\n",
        "                 edge_hidden_feats=128,\n",
        "                 n_tasks=1,\n",
        "                 num_step_message_passing=6,\n",
        "                 num_step_set2set=6,\n",
        "                 num_layer_set2set=3,\n",
        "                 ):\n",
        "\n",
        "        # don't forget to change the class name in super\n",
        "        super(MPNN_modified, self).__init__()\n",
        "\n",
        "        self.gnn = MPNNGNN(node_in_feats=node_in_feats,\n",
        "                           node_out_feats=node_out_feats,\n",
        "                           edge_in_feats=edge_in_feats,\n",
        "                           edge_hidden_feats=edge_hidden_feats,\n",
        "                           num_step_message_passing=num_step_message_passing)\n",
        "        self.readout = Set2Set(input_dim=node_out_feats,\n",
        "                               n_iters=num_step_set2set,\n",
        "                               n_layers=num_layer_set2set)\n",
        "\n",
        "        self.predict = nn.Sequential(\n",
        "            nn.Linear(2 * node_out_feats, node_out_feats),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(node_out_feats, n_tasks)\n",
        "        )\n",
        "\n",
        "    # take in to constant value and multiply the readout output\n",
        "    def forward(self, g, node_feats, edge_feats, constant):\n",
        "\n",
        "        node_feats = self.gnn(g, node_feats, edge_feats)\n",
        "        graph_feats = self.readout(g, node_feats)\n",
        "\n",
        "        #############################################\n",
        "        print(\"Old\",graph_feats,flush=True)\n",
        "\n",
        "        # do the multiplication\n",
        "        new_graph_feats = graph_feats * torch.tensor(constant)\n",
        "\n",
        "        print(\"New\",new_graph_feats,flush=True)\n",
        "\n",
        "        #################################################\n",
        "\n",
        "        return self.predict(new_graph_feats)"
      ],
      "metadata": {
        "id": "f0ywYtZ3NWnU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train this model. You will not see any changes in the model itself."
      ],
      "metadata": {
        "id": "nb0uw3-QNTkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MPNN_modified(node_in_feats = 74,\n",
        "                      edge_in_feats = 12,\n",
        "                      node_out_feats = 64,\n",
        "                      edge_hidden_feats = 128,\n",
        "                      n_tasks = 1,\n",
        "                      num_step_message_passing = 6,\n",
        "                      num_step_set2set = 6,\n",
        "                      num_layer_set2set = 3\n",
        ")\n",
        "model\n"
      ],
      "metadata": {
        "id": "oWO34mInNZjH",
        "outputId": "671b5c22-8e5f-4738-e989-d706103a1453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MPNN_modified(\n",
              "  (gnn): MPNNGNN(\n",
              "    (project_node_feats): Sequential(\n",
              "      (0): Linear(in_features=74, out_features=64, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (gnn_layer): NNConv(\n",
              "      (edge_func): Sequential(\n",
              "        (0): Linear(in_features=12, out_features=128, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=128, out_features=4096, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (gru): GRU(64, 64)\n",
              "  )\n",
              "  (readout): Set2Set(\n",
              "    n_iters=6\n",
              "    (lstm): LSTM(128, 64, num_layers=3)\n",
              "  )\n",
              "  (predict): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will have to change the `run_train_valid` function to include the constant as input to the model"
      ],
      "metadata": {
        "id": "CXZwi2xcNpKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_train_valid_modified(model, optimizer, loss_func,\n",
        "                    train_dataloader, valid_dataloader):\n",
        "\n",
        "      epochs = 1\n",
        "\n",
        "      # loop over epochs\n",
        "      for epoch in range(epochs):\n",
        "        print(\"\\nStarting Epoch\", epoch+1)\n",
        "\n",
        "        # set the model to train so the parameters can be updated\n",
        "        model.train()\n",
        "        # loop over training batches\n",
        "\n",
        "        train_loss = []\n",
        "        for batch in train_dataloader:\n",
        "\n",
        "          # Do a forward pass\n",
        "          batch_graph, target = batch\n",
        "\n",
        "          # look at the forward function for input\n",
        "          # this model needs graph, node_feats and edge_feats\n",
        "          node_feats = batch_graph.ndata[\"hv\"]\n",
        "          edge_feats = batch_graph.edata[\"he\"]\n",
        "\n",
        "          ###################################################\n",
        "          # adding the constant\n",
        "          predictions = model(batch_graph, node_feats, edge_feats, 10)\n",
        "          ######################################################\n",
        "\n",
        "\n",
        "          # Compute loss\n",
        "          loss = (loss_func(predictions, target)).mean()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Do back propogation and update gradient\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # save loss to compute average loss\n",
        "          train_loss.append(loss)\n",
        "\n",
        "        print(\"Training loss\", torch.tensor(train_loss).mean().item())\n",
        "\n",
        "\n",
        "\n",
        "        # set the model to eval so the parameters are not updated\n",
        "        model.eval()\n",
        "        valid_loss = []\n",
        "\n",
        "        # loop over validation batches\n",
        "        with torch.no_grad():\n",
        "          for batch in valid_dataloader:\n",
        "\n",
        "            # Do a forward pass\n",
        "            batch_graph, target = batch\n",
        "            node_feats = batch_graph.ndata[\"hv\"]\n",
        "            edge_feats = batch_graph.edata[\"he\"]\n",
        "\n",
        "            #####################################################\n",
        "            # adding the constant\n",
        "            predictions = model(batch_graph, node_feats, edge_feats, 10)\n",
        "            #######################################################\n",
        "\n",
        "            # Compute loss and gradient\n",
        "            loss = (loss_func(predictions, target)).mean()\n",
        "\n",
        "            # save loss to compute average loss\n",
        "            valid_loss.append(loss)\n",
        "\n",
        "        print(\"Validation loss\", torch.tensor(valid_loss).mean().item())\n"
      ],
      "metadata": {
        "id": "ECWrVBCgNclF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally train the model"
      ],
      "metadata": {
        "id": "H9KXWbmVOLnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adam optimier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "run_train_valid_modified(model=model, loss_func=loss_func,\n",
        "                optimizer=optimizer, train_dataloader=train_dataloader,\n",
        "                valid_dataloader=valid_dataloader)"
      ],
      "metadata": {
        "id": "5SpP5OWiOGcw",
        "outputId": "82c204d3-a127-49df-d882-9bf69a30b0a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Epoch 1\n",
            "Old tensor([[-0.0524, -0.0862, -0.0660,  ..., -0.1515, -0.2681, -0.1118],\n",
            "        [-0.0529, -0.0879, -0.0648,  ..., -0.1740, -0.2036, -0.1208],\n",
            "        [-0.0527, -0.0868, -0.0657,  ..., -0.1448, -0.2510, -0.1140],\n",
            "        ...,\n",
            "        [-0.0528, -0.0866, -0.0656,  ..., -0.1587, -0.2541, -0.0838],\n",
            "        [-0.0523, -0.0850, -0.0664,  ..., -0.1547, -0.3155, -0.0736],\n",
            "        [-0.0528, -0.0863, -0.0660,  ..., -0.1573, -0.2596, -0.0808]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.5244, -0.8620, -0.6597,  ..., -1.5145, -2.6806, -1.1184],\n",
            "        [-0.5288, -0.8795, -0.6485,  ..., -1.7403, -2.0362, -1.2077],\n",
            "        [-0.5267, -0.8677, -0.6568,  ..., -1.4481, -2.5097, -1.1401],\n",
            "        ...,\n",
            "        [-0.5275, -0.8661, -0.6564,  ..., -1.5873, -2.5407, -0.8382],\n",
            "        [-0.5227, -0.8503, -0.6638,  ..., -1.5470, -3.1552, -0.7362],\n",
            "        [-0.5278, -0.8634, -0.6595,  ..., -1.5726, -2.5956, -0.8080]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0567, -0.0823, -0.0579,  ..., -0.1753, -0.1574, -0.2620],\n",
            "        [-0.0568, -0.0823, -0.0584,  ..., -0.1648, -0.1515, -0.2462],\n",
            "        [-0.0580, -0.0831, -0.0586,  ..., -0.1584, -0.1409, -0.2926],\n",
            "        ...,\n",
            "        [-0.0564, -0.0824, -0.0579,  ..., -0.1740, -0.1570, -0.2557],\n",
            "        [-0.0578, -0.0831, -0.0586,  ..., -0.1504, -0.1568, -0.2924],\n",
            "        [-0.0557, -0.0821, -0.0586,  ..., -0.1769, -0.1579, -0.3151]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.5669, -0.8233, -0.5789,  ..., -1.7528, -1.5741, -2.6203],\n",
            "        [-0.5679, -0.8232, -0.5835,  ..., -1.6483, -1.5153, -2.4623],\n",
            "        [-0.5802, -0.8310, -0.5859,  ..., -1.5839, -1.4091, -2.9258],\n",
            "        ...,\n",
            "        [-0.5640, -0.8244, -0.5786,  ..., -1.7404, -1.5703, -2.5568],\n",
            "        [-0.5777, -0.8311, -0.5855,  ..., -1.5042, -1.5679, -2.9242],\n",
            "        [-0.5566, -0.8207, -0.5861,  ..., -1.7688, -1.5795, -3.1515]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0607, -0.0843, -0.0570,  ..., -0.1395, -0.1502, -0.2176],\n",
            "        [-0.0593, -0.0834, -0.0573,  ..., -0.1304, -0.1347, -0.2080],\n",
            "        [-0.0607, -0.0840, -0.0564,  ..., -0.1522, -0.1310, -0.1875],\n",
            "        ...,\n",
            "        [-0.0596, -0.0837, -0.0571,  ..., -0.1223, -0.1301, -0.1962],\n",
            "        [-0.0595, -0.0835, -0.0574,  ..., -0.1249, -0.1326, -0.1967],\n",
            "        [-0.0605, -0.0840, -0.0566,  ..., -0.1455, -0.1332, -0.1759]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.6073, -0.8431, -0.5701,  ..., -1.3950, -1.5017, -2.1761],\n",
            "        [-0.5930, -0.8335, -0.5731,  ..., -1.3041, -1.3473, -2.0805],\n",
            "        [-0.6067, -0.8398, -0.5641,  ..., -1.5218, -1.3095, -1.8749],\n",
            "        ...,\n",
            "        [-0.5958, -0.8374, -0.5713,  ..., -1.2225, -1.3011, -1.9620],\n",
            "        [-0.5953, -0.8348, -0.5741,  ..., -1.2490, -1.3264, -1.9666],\n",
            "        [-0.6051, -0.8403, -0.5657,  ..., -1.4550, -1.3318, -1.7592]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0609, -0.0849, -0.0556,  ..., -0.1085, -0.1195, -0.1378],\n",
            "        [-0.0597, -0.0840, -0.0563,  ..., -0.1244, -0.1141, -0.1789],\n",
            "        [-0.0615, -0.0854, -0.0551,  ..., -0.1337, -0.1234, -0.1382],\n",
            "        ...,\n",
            "        [-0.0609, -0.0851, -0.0555,  ..., -0.1180, -0.1172, -0.1452],\n",
            "        [-0.0618, -0.0857, -0.0548,  ..., -0.1445, -0.1225, -0.1453],\n",
            "        [-0.0619, -0.0855, -0.0553,  ..., -0.1430, -0.1199, -0.1569]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.6086, -0.8494, -0.5561,  ..., -1.0852, -1.1954, -1.3777],\n",
            "        [-0.5970, -0.8401, -0.5635,  ..., -1.2437, -1.1408, -1.7891],\n",
            "        [-0.6153, -0.8536, -0.5513,  ..., -1.3367, -1.2340, -1.3822],\n",
            "        ...,\n",
            "        [-0.6088, -0.8508, -0.5548,  ..., -1.1801, -1.1723, -1.4519],\n",
            "        [-0.6180, -0.8567, -0.5481,  ..., -1.4448, -1.2246, -1.4526],\n",
            "        [-0.6194, -0.8555, -0.5533,  ..., -1.4295, -1.1991, -1.5691]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0634, -0.0870, -0.0537,  ..., -0.1314, -0.1160, -0.1182],\n",
            "        [-0.0624, -0.0862, -0.0546,  ..., -0.1034, -0.1186, -0.1313],\n",
            "        [-0.0626, -0.0861, -0.0546,  ..., -0.1025, -0.1237, -0.1231],\n",
            "        ...,\n",
            "        [-0.0629, -0.0867, -0.0542,  ..., -0.1233, -0.1129, -0.1243],\n",
            "        [-0.0620, -0.0856, -0.0546,  ..., -0.1065, -0.1296, -0.1403],\n",
            "        [-0.0634, -0.0874, -0.0539,  ..., -0.1018, -0.1547, -0.1047]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.6344, -0.8702, -0.5370,  ..., -1.3143, -1.1596, -1.1818],\n",
            "        [-0.6237, -0.8623, -0.5460,  ..., -1.0340, -1.1859, -1.3129],\n",
            "        [-0.6263, -0.8607, -0.5457,  ..., -1.0255, -1.2374, -1.2307],\n",
            "        ...,\n",
            "        [-0.6289, -0.8670, -0.5421,  ..., -1.2325, -1.1289, -1.2432],\n",
            "        [-0.6201, -0.8561, -0.5461,  ..., -1.0654, -1.2961, -1.4029],\n",
            "        [-0.6343, -0.8740, -0.5386,  ..., -1.0185, -1.5471, -1.0475]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0649, -0.0868, -0.0541,  ..., -0.0726, -0.1441, -0.1241],\n",
            "        [-0.0655, -0.0885, -0.0534,  ..., -0.0652, -0.1773, -0.0786],\n",
            "        [-0.0653, -0.0877, -0.0537,  ..., -0.0874, -0.1260, -0.1031],\n",
            "        ...,\n",
            "        [-0.0645, -0.0867, -0.0543,  ..., -0.0563, -0.1550, -0.1406],\n",
            "        [-0.0648, -0.0865, -0.0545,  ..., -0.0472, -0.1467, -0.1448],\n",
            "        [-0.0650, -0.0872, -0.0540,  ..., -0.0740, -0.1382, -0.1219]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.6486, -0.8682, -0.5415,  ..., -0.7255, -1.4407, -1.2412],\n",
            "        [-0.6547, -0.8848, -0.5336,  ..., -0.6517, -1.7730, -0.7856],\n",
            "        [-0.6528, -0.8766, -0.5372,  ..., -0.8742, -1.2596, -1.0312],\n",
            "        ...,\n",
            "        [-0.6449, -0.8674, -0.5427,  ..., -0.5633, -1.5501, -1.4062],\n",
            "        [-0.6476, -0.8652, -0.5447,  ..., -0.4724, -1.4665, -1.4475],\n",
            "        [-0.6497, -0.8715, -0.5399,  ..., -0.7402, -1.3816, -1.2195]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0671, -0.0886, -0.0536,  ..., -0.0311, -0.1565, -0.0980],\n",
            "        [-0.0673, -0.0894, -0.0531,  ..., -0.0377, -0.1980, -0.0581],\n",
            "        [-0.0671, -0.0881, -0.0538,  ..., -0.0171, -0.1709, -0.1174],\n",
            "        ...,\n",
            "        [-0.0671, -0.0885, -0.0536,  ..., -0.0452, -0.1471, -0.1013],\n",
            "        [-0.0671, -0.0889, -0.0532,  ..., -0.0823, -0.1265, -0.0995],\n",
            "        [-0.0671, -0.0883, -0.0539,  ..., -0.0199, -0.1650, -0.1182]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.6713, -0.8857, -0.5358,  ..., -0.3107, -1.5652, -0.9796],\n",
            "        [-0.6730, -0.8945, -0.5311,  ..., -0.3774, -1.9796, -0.5814],\n",
            "        [-0.6713, -0.8809, -0.5376,  ..., -0.1715, -1.7089, -1.1736],\n",
            "        ...,\n",
            "        [-0.6706, -0.8847, -0.5363,  ..., -0.4524, -1.4708, -1.0134],\n",
            "        [-0.6713, -0.8890, -0.5323,  ..., -0.8232, -1.2651, -0.9951],\n",
            "        [-0.6713, -0.8831, -0.5393,  ..., -0.1988, -1.6501, -1.1823]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0688, -0.0884, -0.0533,  ..., -0.0111, -0.1580, -0.1189],\n",
            "        [-0.0687, -0.0888, -0.0532,  ..., -0.0113, -0.1671, -0.1281],\n",
            "        [-0.0688, -0.0884, -0.0533,  ..., -0.0121, -0.1576, -0.1218],\n",
            "        ...,\n",
            "        [-0.0683, -0.0895, -0.0527,  ..., -0.0524, -0.1241, -0.0897],\n",
            "        [-0.0686, -0.0887, -0.0530,  ..., -0.0238, -0.1609, -0.1326],\n",
            "        [-0.0688, -0.0881, -0.0535,  ..., -0.0030, -0.1761, -0.1422]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.6877, -0.8842, -0.5334,  ..., -0.1111, -1.5797, -1.1889],\n",
            "        [-0.6868, -0.8877, -0.5319,  ..., -0.1128, -1.6714, -1.2809],\n",
            "        [-0.6877, -0.8845, -0.5327,  ..., -0.1206, -1.5761, -1.2178],\n",
            "        ...,\n",
            "        [-0.6830, -0.8950, -0.5267,  ..., -0.5237, -1.2412, -0.8972],\n",
            "        [-0.6863, -0.8868, -0.5301,  ..., -0.2376, -1.6095, -1.3259],\n",
            "        [-0.6878, -0.8811, -0.5347,  ..., -0.0297, -1.7607, -1.4221]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0697, -0.0894, -0.0526,  ..., -0.0255, -0.1425, -0.1394],\n",
            "        [-0.0698, -0.0893, -0.0527,  ..., -0.0098, -0.1454, -0.1325],\n",
            "        [-0.0698, -0.0896, -0.0527,  ..., -0.0343, -0.1251, -0.1010],\n",
            "        ...,\n",
            "        [-0.0698, -0.0898, -0.0525,  ..., -0.0250, -0.1353, -0.1102],\n",
            "        [-0.0699, -0.0906, -0.0529,  ..., -0.0504, -0.1825, -0.0392],\n",
            "        [-0.0698, -0.0907, -0.0529,  ..., -0.0485, -0.1871, -0.0368]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.6973, -0.8939, -0.5256,  ..., -0.2551, -1.4252, -1.3936],\n",
            "        [-0.6984, -0.8933, -0.5272,  ..., -0.0979, -1.4541, -1.3245],\n",
            "        [-0.6982, -0.8962, -0.5266,  ..., -0.3429, -1.2505, -1.0101],\n",
            "        ...,\n",
            "        [-0.6976, -0.8980, -0.5250,  ..., -0.2504, -1.3531, -1.1018],\n",
            "        [-0.6990, -0.9062, -0.5288,  ..., -0.5035, -1.8248, -0.3921],\n",
            "        [-0.6980, -0.9069, -0.5286,  ..., -0.4854, -1.8714, -0.3680]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0711, -0.0909, -0.0523,  ..., -0.0429, -0.1254, -0.0897],\n",
            "        [-0.0716, -0.0913, -0.0525,  ..., -0.0316, -0.1850, -0.0260],\n",
            "        [-0.0714, -0.0905, -0.0525,  ..., -0.0225, -0.1372, -0.0983],\n",
            "        ...,\n",
            "        [-0.0715, -0.0907, -0.0526,  ..., -0.0085, -0.1518, -0.1065],\n",
            "        [-0.0717, -0.0902, -0.0527,  ...,  0.0091, -0.1645, -0.1226],\n",
            "        [-0.0716, -0.0903, -0.0525,  ...,  0.0054, -0.1652, -0.1261]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.7113, -0.9090, -0.5227,  ..., -0.4286, -1.2537, -0.8968],\n",
            "        [-0.7156, -0.9130, -0.5251,  ..., -0.3163, -1.8502, -0.2601],\n",
            "        [-0.7143, -0.9054, -0.5253,  ..., -0.2245, -1.3721, -0.9833],\n",
            "        ...,\n",
            "        [-0.7149, -0.9067, -0.5261,  ..., -0.0849, -1.5179, -1.0651],\n",
            "        [-0.7166, -0.9023, -0.5268,  ...,  0.0906, -1.6448, -1.2259],\n",
            "        [-0.7161, -0.9028, -0.5254,  ...,  0.0535, -1.6524, -1.2611]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0730, -0.0913, -0.0523,  ..., -0.0134, -0.1577, -0.1043],\n",
            "        [-0.0730, -0.0926, -0.0524,  ..., -0.0098, -0.2000, -0.0149],\n",
            "        [-0.0730, -0.0912, -0.0523,  ..., -0.0028, -0.1562, -0.1091],\n",
            "        ...,\n",
            "        [-0.0727, -0.0915, -0.0521,  ..., -0.0486, -0.1316, -0.0861],\n",
            "        [-0.0730, -0.0914, -0.0523,  ..., -0.0138, -0.1544, -0.1031],\n",
            "        [-0.0729, -0.0913, -0.0522,  ..., -0.0209, -0.1504, -0.1018]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.7301, -0.9132, -0.5226,  ..., -0.1336, -1.5771, -1.0433],\n",
            "        [-0.7304, -0.9260, -0.5241,  ..., -0.0978, -1.9998, -0.1494],\n",
            "        [-0.7303, -0.9119, -0.5232,  ..., -0.0282, -1.5619, -1.0915],\n",
            "        ...,\n",
            "        [-0.7269, -0.9149, -0.5206,  ..., -0.4857, -1.3160, -0.8609],\n",
            "        [-0.7300, -0.9139, -0.5227,  ..., -0.1376, -1.5439, -1.0312],\n",
            "        [-0.7289, -0.9128, -0.5216,  ..., -0.2094, -1.5042, -1.0182]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0745, -0.0917, -0.0524,  ...,  0.0420, -0.1853, -0.1107],\n",
            "        [-0.0748, -0.0912, -0.0526,  ...,  0.0541, -0.2018, -0.1347],\n",
            "        [-0.0745, -0.0915, -0.0525,  ...,  0.0328, -0.1809, -0.1172],\n",
            "        ...,\n",
            "        [-0.0749, -0.0911, -0.0528,  ...,  0.0568, -0.2077, -0.1391],\n",
            "        [-0.0738, -0.0919, -0.0520,  ..., -0.0438, -0.1291, -0.0877],\n",
            "        [-0.0737, -0.0926, -0.0522,  ..., -0.0140, -0.1429, -0.0835]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.7448, -0.9169, -0.5244,  ...,  0.4199, -1.8531, -1.1070],\n",
            "        [-0.7477, -0.9123, -0.5262,  ...,  0.5406, -2.0183, -1.3472],\n",
            "        [-0.7454, -0.9148, -0.5251,  ...,  0.3276, -1.8091, -1.1716],\n",
            "        ...,\n",
            "        [-0.7493, -0.9115, -0.5283,  ...,  0.5681, -2.0770, -1.3912],\n",
            "        [-0.7385, -0.9193, -0.5199,  ..., -0.4379, -1.2912, -0.8771],\n",
            "        [-0.7373, -0.9260, -0.5225,  ..., -0.1401, -1.4292, -0.8354]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0762, -0.0910, -0.0532,  ...,  0.0903, -0.2225, -0.1805],\n",
            "        [-0.0758, -0.0930, -0.0521,  ..., -0.0094, -0.2018, -0.0321],\n",
            "        [-0.0748, -0.0923, -0.0521,  ..., -0.0291, -0.1234, -0.0954],\n",
            "        ...,\n",
            "        [-0.0752, -0.0921, -0.0523,  ...,  0.0116, -0.1535, -0.1155],\n",
            "        [-0.0756, -0.0929, -0.0521,  ..., -0.0177, -0.1881, -0.0417],\n",
            "        [-0.0756, -0.0920, -0.0526,  ...,  0.0504, -0.1824, -0.1229]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.7621, -0.9101, -0.5320,  ...,  0.9030, -2.2246, -1.8054],\n",
            "        [-0.7575, -0.9303, -0.5213,  ..., -0.0939, -2.0182, -0.3209],\n",
            "        [-0.7481, -0.9234, -0.5206,  ..., -0.2912, -1.2338, -0.9536],\n",
            "        ...,\n",
            "        [-0.7522, -0.9211, -0.5229,  ...,  0.1157, -1.5351, -1.1551],\n",
            "        [-0.7556, -0.9285, -0.5208,  ..., -0.1771, -1.8809, -0.4171],\n",
            "        [-0.7559, -0.9197, -0.5255,  ...,  0.5041, -1.8238, -1.2286]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0762, -0.0923, -0.0520,  ...,  0.0058, -0.1489, -0.1051],\n",
            "        [-0.0765, -0.0923, -0.0524,  ...,  0.0607, -0.1843, -0.1427],\n",
            "        [-0.0766, -0.0922, -0.0524,  ...,  0.0570, -0.1869, -0.1425],\n",
            "        ...,\n",
            "        [-0.0767, -0.0919, -0.0524,  ...,  0.0464, -0.1845, -0.1421],\n",
            "        [-0.0767, -0.0921, -0.0523,  ...,  0.0467, -0.1859, -0.1373],\n",
            "        [-0.0767, -0.0921, -0.0523,  ...,  0.0454, -0.1860, -0.1395]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.7617, -0.9231, -0.5196,  ...,  0.0583, -1.4885, -1.0515],\n",
            "        [-0.7651, -0.9232, -0.5239,  ...,  0.6075, -1.8429, -1.4274],\n",
            "        [-0.7658, -0.9219, -0.5237,  ...,  0.5701, -1.8694, -1.4249],\n",
            "        ...,\n",
            "        [-0.7670, -0.9187, -0.5237,  ...,  0.4641, -1.8455, -1.4205],\n",
            "        [-0.7670, -0.9214, -0.5227,  ...,  0.4673, -1.8588, -1.3732],\n",
            "        [-0.7675, -0.9205, -0.5230,  ...,  0.4541, -1.8597, -1.3952]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0776, -0.0938, -0.0516,  ..., -0.0060, -0.1881, -0.0513],\n",
            "        [-0.0772, -0.0927, -0.0517,  ...,  0.0235, -0.1610, -0.1244],\n",
            "        [-0.0775, -0.0933, -0.0513,  ..., -0.0126, -0.1761, -0.0571],\n",
            "        ...,\n",
            "        [-0.0777, -0.0934, -0.0514,  ..., -0.0047, -0.1861, -0.0516],\n",
            "        [-0.0771, -0.0925, -0.0514,  ..., -0.0047, -0.1499, -0.1151],\n",
            "        [-0.0766, -0.0930, -0.0513,  ..., -0.0313, -0.1218, -0.1037]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.7761, -0.9382, -0.5161,  ..., -0.0604, -1.8815, -0.5126],\n",
            "        [-0.7718, -0.9272, -0.5172,  ...,  0.2347, -1.6101, -1.2440],\n",
            "        [-0.7751, -0.9330, -0.5131,  ..., -0.1259, -1.7612, -0.5707],\n",
            "        ...,\n",
            "        [-0.7769, -0.9335, -0.5144,  ..., -0.0467, -1.8612, -0.5155],\n",
            "        [-0.7714, -0.9249, -0.5143,  ..., -0.0470, -1.4988, -1.1505],\n",
            "        [-0.7664, -0.9297, -0.5132,  ..., -0.3126, -1.2183, -1.0368]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0780, -0.0934, -0.0515,  ...,  0.0173, -0.1565, -0.1057],\n",
            "        [-0.0787, -0.0928, -0.0518,  ...,  0.0482, -0.1871, -0.1323],\n",
            "        [-0.0781, -0.0931, -0.0513,  ...,  0.0036, -0.1529, -0.1122],\n",
            "        ...,\n",
            "        [-0.0790, -0.0940, -0.0512,  ...,  0.0051, -0.2054, -0.0313],\n",
            "        [-0.0786, -0.0937, -0.0511,  ..., -0.0055, -0.1835, -0.0494],\n",
            "        [-0.0786, -0.0927, -0.0517,  ...,  0.0535, -0.1888, -0.1415]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.7798, -0.9341, -0.5149,  ...,  0.1726, -1.5647, -1.0572],\n",
            "        [-0.7867, -0.9281, -0.5181,  ...,  0.4822, -1.8710, -1.3234],\n",
            "        [-0.7807, -0.9313, -0.5131,  ...,  0.0361, -1.5293, -1.1222],\n",
            "        ...,\n",
            "        [-0.7896, -0.9399, -0.5121,  ...,  0.0508, -2.0539, -0.3126],\n",
            "        [-0.7857, -0.9366, -0.5107,  ..., -0.0546, -1.8355, -0.4944],\n",
            "        [-0.7858, -0.9271, -0.5170,  ...,  0.5347, -1.8884, -1.4147]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0799, -0.0923, -0.0518,  ...,  0.0703, -0.2121, -0.1554],\n",
            "        [-0.0796, -0.0926, -0.0515,  ...,  0.0362, -0.1866, -0.1331],\n",
            "        [-0.0796, -0.0941, -0.0510,  ...,  0.0095, -0.1930, -0.0342],\n",
            "        ...,\n",
            "        [-0.0791, -0.0933, -0.0514,  ...,  0.0227, -0.1710, -0.1180],\n",
            "        [-0.0786, -0.0936, -0.0511,  ..., -0.0223, -0.1317, -0.0943],\n",
            "        [-0.0794, -0.0928, -0.0515,  ...,  0.0318, -0.1762, -0.1314]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.7992, -0.9232, -0.5179,  ...,  0.7026, -2.1208, -1.5542],\n",
            "        [-0.7957, -0.9262, -0.5154,  ...,  0.3620, -1.8659, -1.3315],\n",
            "        [-0.7961, -0.9413, -0.5095,  ...,  0.0949, -1.9297, -0.3415],\n",
            "        ...,\n",
            "        [-0.7911, -0.9334, -0.5138,  ...,  0.2268, -1.7096, -1.1801],\n",
            "        [-0.7859, -0.9357, -0.5106,  ..., -0.2229, -1.3170, -0.9426],\n",
            "        [-0.7938, -0.9280, -0.5150,  ...,  0.3182, -1.7623, -1.3139]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0803, -0.0947, -0.0509,  ...,  0.0200, -0.2012, -0.0256],\n",
            "        [-0.0806, -0.0927, -0.0517,  ...,  0.0767, -0.2198, -0.1608],\n",
            "        [-0.0800, -0.0943, -0.0509,  ...,  0.0124, -0.1854, -0.0458],\n",
            "        ...,\n",
            "        [-0.0799, -0.0930, -0.0514,  ...,  0.0358, -0.1818, -0.1426],\n",
            "        [-0.0805, -0.0926, -0.0517,  ...,  0.0629, -0.2100, -0.1574],\n",
            "        [-0.0796, -0.0933, -0.0512,  ...,  0.0015, -0.1551, -0.1112]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8028, -0.9467, -0.5090,  ...,  0.1997, -2.0118, -0.2558],\n",
            "        [-0.8064, -0.9269, -0.5168,  ...,  0.7672, -2.1982, -1.6084],\n",
            "        [-0.8000, -0.9426, -0.5088,  ...,  0.1241, -1.8542, -0.4584],\n",
            "        ...,\n",
            "        [-0.7993, -0.9297, -0.5138,  ...,  0.3584, -1.8177, -1.4264],\n",
            "        [-0.8049, -0.9261, -0.5166,  ...,  0.6288, -2.1004, -1.5742],\n",
            "        [-0.7959, -0.9331, -0.5116,  ...,  0.0145, -1.5506, -1.1118]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0803, -0.0943, -0.0510,  ...,  0.0402, -0.2004, -0.0635],\n",
            "        [-0.0802, -0.0934, -0.0513,  ...,  0.0351, -0.1793, -0.1449],\n",
            "        [-0.0798, -0.0935, -0.0509,  ...,  0.0067, -0.1609, -0.1187],\n",
            "        ...,\n",
            "        [-0.0803, -0.0932, -0.0515,  ...,  0.0512, -0.1871, -0.1420],\n",
            "        [-0.0799, -0.0936, -0.0509,  ...,  0.0011, -0.1579, -0.1125],\n",
            "        [-0.0801, -0.0945, -0.0508,  ...,  0.0139, -0.1782, -0.0443]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8032, -0.9428, -0.5098,  ...,  0.4022, -2.0037, -0.6346],\n",
            "        [-0.8024, -0.9341, -0.5134,  ...,  0.3513, -1.7927, -1.4492],\n",
            "        [-0.7983, -0.9349, -0.5089,  ...,  0.0671, -1.6087, -1.1867],\n",
            "        ...,\n",
            "        [-0.8029, -0.9322, -0.5155,  ...,  0.5115, -1.8705, -1.4196],\n",
            "        [-0.7988, -0.9362, -0.5093,  ...,  0.0110, -1.5794, -1.1253],\n",
            "        [-0.8009, -0.9450, -0.5081,  ...,  0.1391, -1.7821, -0.4429]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0796, -0.0944, -0.0510,  ...,  0.0143, -0.1500, -0.1127],\n",
            "        [-0.0804, -0.0948, -0.0507,  ...,  0.0197, -0.1898, -0.0330],\n",
            "        [-0.0804, -0.0935, -0.0512,  ...,  0.0281, -0.1787, -0.1487],\n",
            "        ...,\n",
            "        [-0.0803, -0.0947, -0.0507,  ...,  0.0162, -0.1796, -0.0411],\n",
            "        [-0.0795, -0.0941, -0.0506,  ..., -0.0241, -0.1317, -0.1033],\n",
            "        [-0.0806, -0.0933, -0.0517,  ...,  0.0559, -0.1931, -0.1710]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.7965, -0.9438, -0.5100,  ...,  0.1426, -1.4997, -1.1268],\n",
            "        [-0.8044, -0.9482, -0.5065,  ...,  0.1971, -1.8977, -0.3302],\n",
            "        [-0.8043, -0.9351, -0.5123,  ...,  0.2811, -1.7873, -1.4874],\n",
            "        ...,\n",
            "        [-0.8028, -0.9474, -0.5068,  ...,  0.1620, -1.7956, -0.4108],\n",
            "        [-0.7953, -0.9413, -0.5055,  ..., -0.2412, -1.3168, -1.0332],\n",
            "        [-0.8063, -0.9325, -0.5169,  ...,  0.5585, -1.9313, -1.7101]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0803, -0.0938, -0.0509,  ...,  0.0090, -0.1547, -0.1266],\n",
            "        [-0.0805, -0.0938, -0.0512,  ...,  0.0380, -0.1760, -0.1500],\n",
            "        [-0.0806, -0.0949, -0.0504,  ...,  0.0167, -0.1810, -0.0380],\n",
            "        ...,\n",
            "        [-0.0802, -0.0941, -0.0509,  ...,  0.0148, -0.1571, -0.1342],\n",
            "        [-0.0805, -0.0950, -0.0504,  ...,  0.0154, -0.1795, -0.0372],\n",
            "        [-0.0804, -0.0939, -0.0508,  ...,  0.0075, -0.1584, -0.1166]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8027, -0.9385, -0.5086,  ...,  0.0905, -1.5470, -1.2659],\n",
            "        [-0.8051, -0.9384, -0.5118,  ...,  0.3804, -1.7600, -1.4998],\n",
            "        [-0.8058, -0.9487, -0.5036,  ...,  0.1669, -1.8100, -0.3804],\n",
            "        ...,\n",
            "        [-0.8018, -0.9408, -0.5088,  ...,  0.1482, -1.5712, -1.3423],\n",
            "        [-0.8054, -0.9499, -0.5044,  ...,  0.1542, -1.7945, -0.3721],\n",
            "        [-0.8036, -0.9391, -0.5075,  ...,  0.0750, -1.5835, -1.1660]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0811, -0.0937, -0.0509,  ...,  0.0317, -0.1801, -0.1516],\n",
            "        [-0.0801, -0.0941, -0.0501,  ..., -0.0325, -0.1236, -0.0970],\n",
            "        [-0.0800, -0.0944, -0.0501,  ..., -0.0194, -0.1300, -0.0988],\n",
            "        ...,\n",
            "        [-0.0808, -0.0950, -0.0502,  ...,  0.0172, -0.1781, -0.0375],\n",
            "        [-0.0816, -0.0933, -0.0515,  ...,  0.0790, -0.2128, -0.2025],\n",
            "        [-0.0812, -0.0936, -0.0512,  ...,  0.0539, -0.1898, -0.1740]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8112, -0.9374, -0.5093,  ...,  0.3173, -1.8014, -1.5162],\n",
            "        [-0.8010, -0.9412, -0.5015,  ..., -0.3249, -1.2363, -0.9705],\n",
            "        [-0.7997, -0.9437, -0.5012,  ..., -0.1940, -1.3004, -0.9876],\n",
            "        ...,\n",
            "        [-0.8081, -0.9498, -0.5017,  ...,  0.1720, -1.7810, -0.3752],\n",
            "        [-0.8156, -0.9330, -0.5148,  ...,  0.7900, -2.1279, -2.0246],\n",
            "        [-0.8121, -0.9362, -0.5117,  ...,  0.5389, -1.8980, -1.7401]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0809, -0.0943, -0.0501,  ...,  0.0103, -0.1525, -0.1186],\n",
            "        [-0.0815, -0.0938, -0.0504,  ...,  0.0315, -0.1776, -0.1363],\n",
            "        [-0.0816, -0.0940, -0.0505,  ...,  0.0424, -0.1803, -0.1374],\n",
            "        ...,\n",
            "        [-0.0808, -0.0941, -0.0497,  ..., -0.0281, -0.1346, -0.0982],\n",
            "        [-0.0818, -0.0936, -0.0507,  ...,  0.0561, -0.1939, -0.1687],\n",
            "        [-0.0815, -0.0937, -0.0505,  ...,  0.0294, -0.1742, -0.1468]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8090, -0.9432, -0.5007,  ...,  0.1029, -1.5252, -1.1860],\n",
            "        [-0.8151, -0.9377, -0.5039,  ...,  0.3146, -1.7764, -1.3629],\n",
            "        [-0.8157, -0.9399, -0.5051,  ...,  0.4244, -1.8035, -1.3737],\n",
            "        ...,\n",
            "        [-0.8078, -0.9405, -0.4967,  ..., -0.2810, -1.3461, -0.9825],\n",
            "        [-0.8181, -0.9356, -0.5074,  ...,  0.5610, -1.9391, -1.6872],\n",
            "        [-0.8148, -0.9372, -0.5047,  ...,  0.2939, -1.7416, -1.4683]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-8.1633e-02, -9.4168e-02, -4.9748e-02,  ...,  8.7042e-03,\n",
            "         -1.5482e-01, -1.0848e-01],\n",
            "        [-8.1055e-02, -9.4403e-02, -4.9414e-02,  ..., -1.7692e-02,\n",
            "         -1.2785e-01, -9.3314e-02],\n",
            "        [-8.2209e-02, -9.5259e-02, -4.9272e-02,  ...,  3.3990e-02,\n",
            "         -1.9537e-01,  2.2431e-03],\n",
            "        ...,\n",
            "        [-8.1786e-02, -9.3891e-02, -4.9579e-02,  ..., -2.4401e-03,\n",
            "         -1.5715e-01, -1.2053e-01],\n",
            "        [-8.1713e-02, -9.3910e-02, -4.9697e-02,  ...,  8.5210e-05,\n",
            "         -1.5429e-01, -1.0792e-01],\n",
            "        [-8.2087e-02, -9.3651e-02, -5.0054e-02,  ...,  2.6170e-02,\n",
            "         -1.7441e-01, -1.3958e-01]], grad_fn=<CatBackward0>)\n",
            "New tensor([[-8.1633e-01, -9.4168e-01, -4.9748e-01,  ...,  8.7042e-02,\n",
            "         -1.5482e+00, -1.0848e+00],\n",
            "        [-8.1055e-01, -9.4403e-01, -4.9414e-01,  ..., -1.7692e-01,\n",
            "         -1.2785e+00, -9.3314e-01],\n",
            "        [-8.2209e-01, -9.5259e-01, -4.9272e-01,  ...,  3.3990e-01,\n",
            "         -1.9537e+00,  2.2431e-02],\n",
            "        ...,\n",
            "        [-8.1786e-01, -9.3891e-01, -4.9579e-01,  ..., -2.4401e-02,\n",
            "         -1.5715e+00, -1.2053e+00],\n",
            "        [-8.1713e-01, -9.3910e-01, -4.9697e-01,  ...,  8.5210e-04,\n",
            "         -1.5429e+00, -1.0792e+00],\n",
            "        [-8.2087e-01, -9.3651e-01, -5.0054e-01,  ...,  2.6170e-01,\n",
            "         -1.7441e+00, -1.3958e+00]], grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0822, -0.0939, -0.0494,  ...,  0.0012, -0.1552, -0.1067],\n",
            "        [-0.0826, -0.0937, -0.0497,  ...,  0.0264, -0.1787, -0.1326],\n",
            "        [-0.0817, -0.0942, -0.0489,  ..., -0.0205, -0.1421, -0.0936],\n",
            "        ...,\n",
            "        [-0.0830, -0.0934, -0.0502,  ...,  0.0705, -0.2047, -0.1613],\n",
            "        [-0.0833, -0.0934, -0.0502,  ...,  0.0755, -0.2140, -0.1750],\n",
            "        [-0.0815, -0.0943, -0.0490,  ..., -0.0212, -0.1309, -0.0904]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8219, -0.9388, -0.4943,  ...,  0.0120, -1.5519, -1.0673],\n",
            "        [-0.8261, -0.9369, -0.4970,  ...,  0.2642, -1.7868, -1.3264],\n",
            "        [-0.8174, -0.9416, -0.4894,  ..., -0.2053, -1.4212, -0.9363],\n",
            "        ...,\n",
            "        [-0.8304, -0.9337, -0.5022,  ...,  0.7051, -2.0468, -1.6133],\n",
            "        [-0.8325, -0.9337, -0.5024,  ...,  0.7554, -2.1404, -1.7501],\n",
            "        [-0.8153, -0.9434, -0.4903,  ..., -0.2116, -1.3094, -0.9036]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0824, -0.0945, -0.0490,  ...,  0.0356, -0.1749, -0.0579],\n",
            "        [-0.0825, -0.0936, -0.0494,  ...,  0.0288, -0.1786, -0.1400],\n",
            "        [-0.0828, -0.0935, -0.0497,  ...,  0.0471, -0.1904, -0.1587],\n",
            "        ...,\n",
            "        [-0.0821, -0.0940, -0.0491,  ..., -0.0004, -0.1523, -0.1021],\n",
            "        [-0.0820, -0.0940, -0.0489,  ..., -0.0053, -0.1507, -0.1092],\n",
            "        [-0.0828, -0.0935, -0.0496,  ...,  0.0516, -0.1922, -0.1601]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8236, -0.9453, -0.4905,  ...,  0.3556, -1.7492, -0.5790],\n",
            "        [-0.8254, -0.9365, -0.4940,  ...,  0.2878, -1.7861, -1.4002],\n",
            "        [-0.8281, -0.9351, -0.4973,  ...,  0.4706, -1.9035, -1.5873],\n",
            "        ...,\n",
            "        [-0.8211, -0.9397, -0.4915,  ..., -0.0037, -1.5230, -1.0208],\n",
            "        [-0.8203, -0.9396, -0.4889,  ..., -0.0533, -1.5065, -1.0922],\n",
            "        [-0.8277, -0.9353, -0.4965,  ...,  0.5163, -1.9222, -1.6013]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0819, -0.0940, -0.0490,  ...,  0.0024, -0.1534, -0.1060],\n",
            "        [-0.0819, -0.0939, -0.0488,  ..., -0.0008, -0.1542, -0.1110],\n",
            "        [-0.0820, -0.0938, -0.0489,  ...,  0.0050, -0.1598, -0.1129],\n",
            "        ...,\n",
            "        [-0.0816, -0.0949, -0.0485,  ...,  0.0153, -0.1520, -0.0415],\n",
            "        [-0.0826, -0.0936, -0.0495,  ...,  0.0483, -0.1905, -0.1564],\n",
            "        [-0.0825, -0.0935, -0.0497,  ...,  0.0483, -0.1870, -0.1645]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8192, -0.9404, -0.4897,  ...,  0.0243, -1.5338, -1.0598],\n",
            "        [-0.8192, -0.9392, -0.4885,  ..., -0.0080, -1.5422, -1.1097],\n",
            "        [-0.8199, -0.9384, -0.4891,  ...,  0.0504, -1.5976, -1.1293],\n",
            "        ...,\n",
            "        [-0.8162, -0.9493, -0.4853,  ...,  0.1527, -1.5202, -0.4154],\n",
            "        [-0.8265, -0.9360, -0.4952,  ...,  0.4834, -1.9052, -1.5638],\n",
            "        [-0.8252, -0.9348, -0.4966,  ...,  0.4834, -1.8701, -1.6445]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0815, -0.0946, -0.0483,  ...,  0.0049, -0.1556, -0.0405],\n",
            "        [-0.0815, -0.0941, -0.0489,  ...,  0.0069, -0.1473, -0.1032],\n",
            "        [-0.0815, -0.0940, -0.0488,  ..., -0.0056, -0.1497, -0.1135],\n",
            "        ...,\n",
            "        [-0.0819, -0.0938, -0.0491,  ...,  0.0283, -0.1711, -0.1306],\n",
            "        [-0.0816, -0.0949, -0.0483,  ...,  0.0178, -0.1643, -0.0264],\n",
            "        [-0.0820, -0.0940, -0.0493,  ...,  0.0337, -0.1718, -0.1405]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8147, -0.9463, -0.4830,  ...,  0.0495, -1.5563, -0.4052],\n",
            "        [-0.8145, -0.9414, -0.4894,  ...,  0.0685, -1.4726, -1.0316],\n",
            "        [-0.8150, -0.9397, -0.4878,  ..., -0.0555, -1.4968, -1.1350],\n",
            "        ...,\n",
            "        [-0.8192, -0.9380, -0.4913,  ...,  0.2833, -1.7112, -1.3061],\n",
            "        [-0.8163, -0.9486, -0.4834,  ...,  0.1775, -1.6431, -0.2644],\n",
            "        [-0.8196, -0.9397, -0.4934,  ...,  0.3371, -1.7177, -1.4045]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0816, -0.0940, -0.0491,  ...,  0.0278, -0.1641, -0.1463],\n",
            "        [-0.0818, -0.0938, -0.0491,  ...,  0.0248, -0.1650, -0.1349],\n",
            "        [-0.0811, -0.0940, -0.0483,  ..., -0.0278, -0.1305, -0.0943],\n",
            "        ...,\n",
            "        [-0.0816, -0.0939, -0.0490,  ...,  0.0208, -0.1600, -0.1270],\n",
            "        [-0.0818, -0.0939, -0.0489,  ...,  0.0236, -0.1669, -0.1271],\n",
            "        [-0.0821, -0.0935, -0.0495,  ...,  0.0489, -0.1843, -0.1618]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8156, -0.9402, -0.4910,  ...,  0.2780, -1.6408, -1.4627],\n",
            "        [-0.8178, -0.9383, -0.4914,  ...,  0.2479, -1.6496, -1.3488],\n",
            "        [-0.8107, -0.9405, -0.4832,  ..., -0.2776, -1.3050, -0.9426],\n",
            "        ...,\n",
            "        [-0.8163, -0.9391, -0.4903,  ...,  0.2082, -1.5998, -1.2704],\n",
            "        [-0.8177, -0.9388, -0.4893,  ...,  0.2361, -1.6694, -1.2707],\n",
            "        [-0.8210, -0.9354, -0.4947,  ...,  0.4886, -1.8427, -1.6178]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0810, -0.0942, -0.0482,  ..., -0.0252, -0.1235, -0.0929],\n",
            "        [-0.0822, -0.0934, -0.0493,  ...,  0.0479, -0.1829, -0.1695],\n",
            "        [-0.0819, -0.0937, -0.0489,  ...,  0.0241, -0.1668, -0.1454],\n",
            "        ...,\n",
            "        [-0.0819, -0.0938, -0.0488,  ...,  0.0273, -0.1659, -0.1389],\n",
            "        [-0.0822, -0.0935, -0.0492,  ...,  0.0464, -0.1816, -0.1634],\n",
            "        [-0.0822, -0.0936, -0.0490,  ...,  0.0417, -0.1785, -0.1576]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8104, -0.9419, -0.4817,  ..., -0.2516, -1.2348, -0.9285],\n",
            "        [-0.8219, -0.9339, -0.4929,  ...,  0.4793, -1.8290, -1.6951],\n",
            "        [-0.8191, -0.9371, -0.4888,  ...,  0.2408, -1.6683, -1.4543],\n",
            "        ...,\n",
            "        [-0.8191, -0.9378, -0.4884,  ...,  0.2735, -1.6590, -1.3887],\n",
            "        [-0.8223, -0.9354, -0.4924,  ...,  0.4637, -1.8164, -1.6341],\n",
            "        [-0.8216, -0.9361, -0.4902,  ...,  0.4169, -1.7848, -1.5764]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0819, -0.0946, -0.0479,  ...,  0.0100, -0.1508, -0.0354],\n",
            "        [-0.0818, -0.0940, -0.0481,  ..., -0.0215, -0.1345, -0.0878],\n",
            "        [-0.0826, -0.0934, -0.0489,  ...,  0.0444, -0.1814, -0.1547],\n",
            "        ...,\n",
            "        [-0.0821, -0.0939, -0.0488,  ...,  0.0335, -0.1653, -0.1386],\n",
            "        [-0.0827, -0.0934, -0.0490,  ...,  0.0435, -0.1829, -0.1649],\n",
            "        [-0.0820, -0.0937, -0.0482,  ...,  0.0011, -0.1515, -0.1134]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8190, -0.9458, -0.4785,  ...,  0.0995, -1.5077, -0.3535],\n",
            "        [-0.8176, -0.9396, -0.4811,  ..., -0.2150, -1.3453, -0.8784],\n",
            "        [-0.8263, -0.9343, -0.4894,  ...,  0.4438, -1.8142, -1.5472],\n",
            "        ...,\n",
            "        [-0.8215, -0.9390, -0.4880,  ...,  0.3353, -1.6527, -1.3858],\n",
            "        [-0.8267, -0.9341, -0.4901,  ...,  0.4352, -1.8287, -1.6486],\n",
            "        [-0.8203, -0.9374, -0.4823,  ...,  0.0113, -1.5150, -1.1338]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0834, -0.0931, -0.0489,  ...,  0.0597, -0.1953, -0.1725],\n",
            "        [-0.0823, -0.0940, -0.0482,  ...,  0.0030, -0.1484, -0.1213],\n",
            "        [-0.0820, -0.0946, -0.0476,  ...,  0.0041, -0.1374, -0.0501],\n",
            "        ...,\n",
            "        [-0.0829, -0.0935, -0.0484,  ...,  0.0218, -0.1696, -0.1372],\n",
            "        [-0.0827, -0.0936, -0.0482,  ...,  0.0153, -0.1627, -0.1251],\n",
            "        [-0.0821, -0.0939, -0.0476,  ..., -0.0264, -0.1348, -0.0918]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8336, -0.9312, -0.4887,  ...,  0.5967, -1.9526, -1.7254],\n",
            "        [-0.8234, -0.9399, -0.4815,  ...,  0.0301, -1.4843, -1.2128],\n",
            "        [-0.8204, -0.9460, -0.4759,  ...,  0.0410, -1.3741, -0.5011],\n",
            "        ...,\n",
            "        [-0.8289, -0.9346, -0.4840,  ...,  0.2183, -1.6958, -1.3720],\n",
            "        [-0.8274, -0.9357, -0.4823,  ...,  0.1530, -1.6274, -1.2509],\n",
            "        [-0.8211, -0.9389, -0.4760,  ..., -0.2644, -1.3481, -0.9181]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0831, -0.0934, -0.0481,  ...,  0.0216, -0.1667, -0.1390],\n",
            "        [-0.0827, -0.0947, -0.0475,  ...,  0.0139, -0.1504, -0.0332],\n",
            "        [-0.0834, -0.0931, -0.0485,  ...,  0.0353, -0.1798, -0.1558],\n",
            "        ...,\n",
            "        [-0.0832, -0.0934, -0.0481,  ...,  0.0169, -0.1670, -0.1402],\n",
            "        [-0.0827, -0.0946, -0.0474,  ...,  0.0103, -0.1510, -0.0341],\n",
            "        [-0.0829, -0.0945, -0.0477,  ...,  0.0299, -0.1641, -0.0432]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8313, -0.9341, -0.4811,  ...,  0.2161, -1.6671, -1.3899],\n",
            "        [-0.8270, -0.9471, -0.4749,  ...,  0.1387, -1.5039, -0.3321],\n",
            "        [-0.8341, -0.9314, -0.4845,  ...,  0.3532, -1.7979, -1.5580],\n",
            "        ...,\n",
            "        [-0.8318, -0.9338, -0.4814,  ...,  0.1686, -1.6699, -1.4019],\n",
            "        [-0.8270, -0.9461, -0.4741,  ...,  0.1034, -1.5101, -0.3410],\n",
            "        [-0.8286, -0.9447, -0.4770,  ...,  0.2987, -1.6408, -0.4323]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0828, -0.0937, -0.0478,  ...,  0.0021, -0.1478, -0.1194],\n",
            "        [-0.0834, -0.0931, -0.0484,  ...,  0.0416, -0.1789, -0.1674],\n",
            "        [-0.0825, -0.0938, -0.0475,  ..., -0.0323, -0.1265, -0.0873],\n",
            "        ...,\n",
            "        [-0.0829, -0.0935, -0.0476,  ..., -0.0035, -0.1531, -0.1158],\n",
            "        [-0.0830, -0.0935, -0.0478,  ..., -0.0021, -0.1491, -0.1115],\n",
            "        [-0.0833, -0.0933, -0.0481,  ...,  0.0154, -0.1671, -0.1308]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8283, -0.9369, -0.4784,  ...,  0.0206, -1.4782, -1.1943],\n",
            "        [-0.8344, -0.9315, -0.4843,  ...,  0.4164, -1.7888, -1.6745],\n",
            "        [-0.8254, -0.9378, -0.4748,  ..., -0.3227, -1.2648, -0.8725],\n",
            "        ...,\n",
            "        [-0.8292, -0.9349, -0.4756,  ..., -0.0348, -1.5308, -1.1580],\n",
            "        [-0.8295, -0.9354, -0.4784,  ..., -0.0211, -1.4914, -1.1148],\n",
            "        [-0.8329, -0.9334, -0.4807,  ...,  0.1536, -1.6712, -1.3077]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0831, -0.0933, -0.0481,  ...,  0.0193, -0.1606, -0.1328],\n",
            "        [-0.0825, -0.0939, -0.0477,  ..., -0.0009, -0.1370, -0.1038],\n",
            "        [-0.0831, -0.0934, -0.0479,  ...,  0.0122, -0.1613, -0.1360],\n",
            "        ...,\n",
            "        [-0.0832, -0.0935, -0.0480,  ...,  0.0159, -0.1620, -0.1274],\n",
            "        [-0.0825, -0.0945, -0.0472,  ...,  0.0084, -0.1418, -0.0405],\n",
            "        [-0.0834, -0.0931, -0.0483,  ...,  0.0354, -0.1786, -0.1542]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8306, -0.9333, -0.4813,  ...,  0.1929, -1.6061, -1.3280],\n",
            "        [-0.8250, -0.9389, -0.4770,  ..., -0.0085, -1.3703, -1.0379],\n",
            "        [-0.8308, -0.9345, -0.4789,  ...,  0.1219, -1.6134, -1.3599],\n",
            "        ...,\n",
            "        [-0.8317, -0.9348, -0.4803,  ...,  0.1595, -1.6195, -1.2738],\n",
            "        [-0.8246, -0.9453, -0.4724,  ...,  0.0838, -1.4184, -0.4051],\n",
            "        [-0.8341, -0.9315, -0.4830,  ...,  0.3541, -1.7863, -1.5416]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0829, -0.0933, -0.0481,  ...,  0.0196, -0.1661, -0.1353],\n",
            "        [-0.0823, -0.0944, -0.0471,  ..., -0.0024, -0.1362, -0.0408],\n",
            "        [-0.0833, -0.0929, -0.0487,  ...,  0.0557, -0.1878, -0.1779],\n",
            "        ...,\n",
            "        [-0.0824, -0.0939, -0.0478,  ...,  0.0033, -0.1453, -0.1015],\n",
            "        [-0.0829, -0.0933, -0.0482,  ...,  0.0243, -0.1635, -0.1379],\n",
            "        [-0.0828, -0.0935, -0.0483,  ...,  0.0268, -0.1607, -0.1352]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8293, -0.9330, -0.4811,  ...,  0.1957, -1.6612, -1.3533],\n",
            "        [-0.8226, -0.9439, -0.4714,  ..., -0.0235, -1.3622, -0.4079],\n",
            "        [-0.8331, -0.9287, -0.4868,  ...,  0.5569, -1.8779, -1.7787],\n",
            "        ...,\n",
            "        [-0.8242, -0.9385, -0.4777,  ...,  0.0327, -1.4525, -1.0145],\n",
            "        [-0.8290, -0.9329, -0.4825,  ...,  0.2434, -1.6346, -1.3790],\n",
            "        [-0.8280, -0.9352, -0.4825,  ...,  0.2684, -1.6074, -1.3517]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0820, -0.0945, -0.0472,  ...,  0.0056, -0.1382, -0.0313],\n",
            "        [-0.0821, -0.0943, -0.0473,  ...,  0.0033, -0.1426, -0.0464],\n",
            "        [-0.0828, -0.0932, -0.0485,  ...,  0.0399, -0.1731, -0.1586],\n",
            "        ...,\n",
            "        [-0.0825, -0.0935, -0.0479,  ...,  0.0009, -0.1536, -0.1177],\n",
            "        [-0.0823, -0.0936, -0.0478,  ..., -0.0014, -0.1518, -0.1076],\n",
            "        [-0.0820, -0.0939, -0.0478,  ..., -0.0004, -0.1379, -0.1141]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8200, -0.9448, -0.4718,  ...,  0.0561, -1.3816, -0.3130],\n",
            "        [-0.8206, -0.9428, -0.4727,  ...,  0.0330, -1.4258, -0.4641],\n",
            "        [-0.8280, -0.9316, -0.4853,  ...,  0.3991, -1.7307, -1.5857],\n",
            "        ...,\n",
            "        [-0.8246, -0.9351, -0.4791,  ...,  0.0093, -1.5364, -1.1771],\n",
            "        [-0.8233, -0.9356, -0.4779,  ..., -0.0144, -1.5176, -1.0760],\n",
            "        [-0.8197, -0.9395, -0.4777,  ..., -0.0036, -1.3788, -1.1409]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0826, -0.0932, -0.0485,  ...,  0.0381, -0.1697, -0.1528],\n",
            "        [-0.0821, -0.0936, -0.0479,  ..., -0.0032, -0.1430, -0.1114],\n",
            "        [-0.0824, -0.0934, -0.0482,  ...,  0.0211, -0.1572, -0.1418],\n",
            "        ...,\n",
            "        [-0.0819, -0.0945, -0.0471,  ...,  0.0068, -0.1406, -0.0246],\n",
            "        [-0.0817, -0.0939, -0.0476,  ..., -0.0209, -0.1266, -0.0843],\n",
            "        [-0.0823, -0.0936, -0.0482,  ...,  0.0221, -0.1543, -0.1271]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8263, -0.9323, -0.4845,  ...,  0.3811, -1.6966, -1.5282],\n",
            "        [-0.8212, -0.9358, -0.4787,  ..., -0.0317, -1.4296, -1.1139],\n",
            "        [-0.8238, -0.9344, -0.4825,  ...,  0.2109, -1.5715, -1.4181],\n",
            "        ...,\n",
            "        [-0.8194, -0.9454, -0.4713,  ...,  0.0685, -1.4063, -0.2458],\n",
            "        [-0.8174, -0.9385, -0.4763,  ..., -0.2090, -1.2657, -0.8433],\n",
            "        [-0.8227, -0.9358, -0.4819,  ...,  0.2206, -1.5433, -1.2710]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-8.1950e-02, -9.4309e-02, -4.7212e-02,  ...,  8.5081e-03,\n",
            "         -1.4074e-01, -3.4849e-02],\n",
            "        [-8.2084e-02, -9.3735e-02, -4.7821e-02,  ...,  1.1348e-03,\n",
            "         -1.4180e-01, -1.0764e-01],\n",
            "        [-8.2032e-02, -9.4348e-02, -4.7292e-02,  ...,  6.1624e-03,\n",
            "         -1.4375e-01, -2.9388e-02],\n",
            "        ...,\n",
            "        [-8.1791e-02, -9.3670e-02, -4.7378e-02,  ..., -2.9615e-02,\n",
            "         -1.2542e-01, -8.8276e-02],\n",
            "        [-8.2147e-02, -9.3676e-02, -4.7853e-02,  ..., -1.3138e-04,\n",
            "         -1.4381e-01, -1.0527e-01],\n",
            "        [-8.2694e-02, -9.3170e-02, -4.8483e-02,  ...,  4.2988e-02,\n",
            "         -1.7122e-01, -1.6116e-01]], grad_fn=<CatBackward0>)\n",
            "New tensor([[-8.1950e-01, -9.4309e-01, -4.7212e-01,  ...,  8.5081e-02,\n",
            "         -1.4074e+00, -3.4849e-01],\n",
            "        [-8.2084e-01, -9.3735e-01, -4.7821e-01,  ...,  1.1348e-02,\n",
            "         -1.4180e+00, -1.0764e+00],\n",
            "        [-8.2032e-01, -9.4348e-01, -4.7292e-01,  ...,  6.1624e-02,\n",
            "         -1.4375e+00, -2.9388e-01],\n",
            "        ...,\n",
            "        [-8.1791e-01, -9.3670e-01, -4.7378e-01,  ..., -2.9615e-01,\n",
            "         -1.2542e+00, -8.8276e-01],\n",
            "        [-8.2147e-01, -9.3676e-01, -4.7853e-01,  ..., -1.3138e-03,\n",
            "         -1.4381e+00, -1.0527e+00],\n",
            "        [-8.2694e-01, -9.3170e-01, -4.8483e-01,  ...,  4.2988e-01,\n",
            "         -1.7122e+00, -1.6116e+00]], grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0821, -0.0936, -0.0476,  ..., -0.0026, -0.1349, -0.1071],\n",
            "        [-0.0826, -0.0931, -0.0480,  ...,  0.0180, -0.1573, -0.1371],\n",
            "        [-0.0829, -0.0930, -0.0482,  ...,  0.0402, -0.1710, -0.1496],\n",
            "        ...,\n",
            "        [-0.0822, -0.0936, -0.0477,  ...,  0.0009, -0.1384, -0.1036],\n",
            "        [-0.0823, -0.0942, -0.0472,  ...,  0.0108, -0.1459, -0.0270],\n",
            "        [-0.0822, -0.0941, -0.0472,  ...,  0.0055, -0.1418, -0.0383]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8211, -0.9358, -0.4758,  ..., -0.0256, -1.3492, -1.0714],\n",
            "        [-0.8262, -0.9315, -0.4799,  ...,  0.1797, -1.5726, -1.3705],\n",
            "        [-0.8291, -0.9303, -0.4822,  ...,  0.4017, -1.7102, -1.4956],\n",
            "        ...,\n",
            "        [-0.8219, -0.9357, -0.4769,  ...,  0.0086, -1.3841, -1.0365],\n",
            "        [-0.8232, -0.9417, -0.4721,  ...,  0.1081, -1.4593, -0.2700],\n",
            "        [-0.8220, -0.9408, -0.4716,  ...,  0.0550, -1.4181, -0.3835]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0824, -0.0944, -0.0469,  ...,  0.0195, -0.1403, -0.0149],\n",
            "        [-0.0823, -0.0943, -0.0469,  ...,  0.0098, -0.1360, -0.0288],\n",
            "        [-0.0822, -0.0936, -0.0472,  ..., -0.0198, -0.1294, -0.0860],\n",
            "        ...,\n",
            "        [-0.0821, -0.0936, -0.0472,  ..., -0.0247, -0.1252, -0.0872],\n",
            "        [-0.0825, -0.0943, -0.0469,  ...,  0.0164, -0.1453, -0.0221],\n",
            "        [-0.0824, -0.0941, -0.0470,  ...,  0.0059, -0.1380, -0.0323]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8236, -0.9444, -0.4688,  ...,  0.1950, -1.4027, -0.1488],\n",
            "        [-0.8230, -0.9429, -0.4686,  ...,  0.0979, -1.3600, -0.2883],\n",
            "        [-0.8223, -0.9357, -0.4724,  ..., -0.1985, -1.2945, -0.8599],\n",
            "        ...,\n",
            "        [-0.8214, -0.9357, -0.4717,  ..., -0.2471, -1.2521, -0.8722],\n",
            "        [-0.8250, -0.9425, -0.4694,  ...,  0.1636, -1.4534, -0.2207],\n",
            "        [-0.8238, -0.9407, -0.4696,  ...,  0.0587, -1.3799, -0.3227]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0836, -0.0927, -0.0482,  ...,  0.0552, -0.1825, -0.1536],\n",
            "        [-0.0832, -0.0930, -0.0479,  ...,  0.0431, -0.1693, -0.1485],\n",
            "        [-0.0828, -0.0933, -0.0476,  ...,  0.0224, -0.1527, -0.1247],\n",
            "        ...,\n",
            "        [-0.0827, -0.0942, -0.0468,  ...,  0.0177, -0.1473, -0.0172],\n",
            "        [-0.0833, -0.0928, -0.0479,  ...,  0.0344, -0.1715, -0.1468],\n",
            "        [-0.0829, -0.0930, -0.0473,  ...,  0.0028, -0.1511, -0.1053]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8357, -0.9269, -0.4819,  ...,  0.5521, -1.8254, -1.5361],\n",
            "        [-0.8315, -0.9298, -0.4792,  ...,  0.4306, -1.6928, -1.4847],\n",
            "        [-0.8283, -0.9328, -0.4760,  ...,  0.2241, -1.5271, -1.2466],\n",
            "        ...,\n",
            "        [-0.8273, -0.9417, -0.4682,  ...,  0.1774, -1.4733, -0.1715],\n",
            "        [-0.8333, -0.9275, -0.4786,  ...,  0.3443, -1.7153, -1.4682],\n",
            "        [-0.8285, -0.9305, -0.4729,  ...,  0.0282, -1.5105, -1.0531]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0836, -0.0925, -0.0481,  ...,  0.0552, -0.1842, -0.1618],\n",
            "        [-0.0821, -0.0936, -0.0468,  ..., -0.0210, -0.1209, -0.0843],\n",
            "        [-0.0833, -0.0929, -0.0480,  ...,  0.0414, -0.1699, -0.1381],\n",
            "        ...,\n",
            "        [-0.0831, -0.0929, -0.0475,  ...,  0.0165, -0.1620, -0.1299],\n",
            "        [-0.0825, -0.0933, -0.0473,  ...,  0.0005, -0.1401, -0.1023],\n",
            "        [-0.0837, -0.0925, -0.0482,  ...,  0.0595, -0.1880, -0.1638]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8358, -0.9251, -0.4814,  ...,  0.5523, -1.8417, -1.6178],\n",
            "        [-0.8206, -0.9361, -0.4681,  ..., -0.2104, -1.2087, -0.8428],\n",
            "        [-0.8327, -0.9294, -0.4796,  ...,  0.4137, -1.6990, -1.3812],\n",
            "        ...,\n",
            "        [-0.8311, -0.9286, -0.4753,  ...,  0.1650, -1.6200, -1.2992],\n",
            "        [-0.8255, -0.9328, -0.4728,  ...,  0.0049, -1.4007, -1.0230],\n",
            "        [-0.8366, -0.9252, -0.4816,  ...,  0.5946, -1.8804, -1.6383]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0827, -0.0930, -0.0473,  ...,  0.0006, -0.1454, -0.1112],\n",
            "        [-0.0829, -0.0935, -0.0474,  ...,  0.0524, -0.1670, -0.0653],\n",
            "        [-0.0832, -0.0927, -0.0477,  ...,  0.0334, -0.1715, -0.1469],\n",
            "        ...,\n",
            "        [-0.0828, -0.0930, -0.0473,  ...,  0.0032, -0.1508, -0.1083],\n",
            "        [-0.0827, -0.0930, -0.0473,  ..., -0.0023, -0.1460, -0.1112],\n",
            "        [-0.0832, -0.0927, -0.0478,  ...,  0.0403, -0.1729, -0.1533]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8269, -0.9303, -0.4731,  ...,  0.0062, -1.4541, -1.1118],\n",
            "        [-0.8293, -0.9354, -0.4740,  ...,  0.5238, -1.6700, -0.6528],\n",
            "        [-0.8319, -0.9269, -0.4773,  ...,  0.3342, -1.7152, -1.4688],\n",
            "        ...,\n",
            "        [-0.8277, -0.9304, -0.4731,  ...,  0.0319, -1.5084, -1.0835],\n",
            "        [-0.8267, -0.9297, -0.4727,  ..., -0.0234, -1.4597, -1.1121],\n",
            "        [-0.8316, -0.9268, -0.4781,  ...,  0.4032, -1.7289, -1.5333]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0829, -0.0927, -0.0476,  ...,  0.0252, -0.1639, -0.1315],\n",
            "        [-0.0825, -0.0938, -0.0468,  ...,  0.0142, -0.1468, -0.0258],\n",
            "        [-0.0827, -0.0930, -0.0475,  ...,  0.0230, -0.1548, -0.1188],\n",
            "        ...,\n",
            "        [-0.0824, -0.0931, -0.0472,  ...,  0.0041, -0.1438, -0.0993],\n",
            "        [-0.0823, -0.0938, -0.0467,  ...,  0.0099, -0.1406, -0.0268],\n",
            "        [-0.0823, -0.0939, -0.0466,  ...,  0.0153, -0.1431, -0.0262]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8291, -0.9271, -0.4761,  ...,  0.2517, -1.6392, -1.3153],\n",
            "        [-0.8245, -0.9375, -0.4679,  ...,  0.1421, -1.4677, -0.2578],\n",
            "        [-0.8267, -0.9301, -0.4752,  ...,  0.2301, -1.5475, -1.1878],\n",
            "        ...,\n",
            "        [-0.8244, -0.9310, -0.4724,  ...,  0.0406, -1.4377, -0.9932],\n",
            "        [-0.8231, -0.9381, -0.4673,  ...,  0.0993, -1.4064, -0.2676],\n",
            "        [-0.8232, -0.9387, -0.4661,  ...,  0.1529, -1.4311, -0.2624]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0823, -0.0941, -0.0465,  ...,  0.0315, -0.1457,  0.0022],\n",
            "        [-0.0823, -0.0930, -0.0473,  ...,  0.0028, -0.1433, -0.1042],\n",
            "        [-0.0826, -0.0928, -0.0475,  ...,  0.0191, -0.1580, -0.1242],\n",
            "        ...,\n",
            "        [-0.0829, -0.0926, -0.0477,  ...,  0.0329, -0.1688, -0.1440],\n",
            "        [-0.0825, -0.0937, -0.0471,  ...,  0.0317, -0.1528, -0.0453],\n",
            "        [-0.0826, -0.0928, -0.0474,  ...,  0.0159, -0.1578, -0.1235]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8226, -0.9415, -0.4653,  ...,  0.3152, -1.4567,  0.0215],\n",
            "        [-0.8234, -0.9304, -0.4726,  ...,  0.0282, -1.4335, -1.0421],\n",
            "        [-0.8263, -0.9279, -0.4745,  ...,  0.1910, -1.5795, -1.2424],\n",
            "        ...,\n",
            "        [-0.8293, -0.9261, -0.4770,  ...,  0.3287, -1.6878, -1.4401],\n",
            "        [-0.8251, -0.9365, -0.4705,  ...,  0.3175, -1.5282, -0.4534],\n",
            "        [-0.8262, -0.9280, -0.4735,  ...,  0.1587, -1.5781, -1.2351]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0817, -0.0933, -0.0467,  ..., -0.0180, -0.1250, -0.0830],\n",
            "        [-0.0821, -0.0930, -0.0469,  ..., -0.0206, -0.1345, -0.0871],\n",
            "        [-0.0830, -0.0924, -0.0479,  ...,  0.0552, -0.1800, -0.1584],\n",
            "        ...,\n",
            "        [-0.0828, -0.0925, -0.0477,  ...,  0.0403, -0.1700, -0.1449],\n",
            "        [-0.0823, -0.0929, -0.0471,  ..., -0.0038, -0.1431, -0.1118],\n",
            "        [-0.0830, -0.0923, -0.0481,  ...,  0.0639, -0.1821, -0.1782]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8174, -0.9335, -0.4675,  ..., -0.1801, -1.2500, -0.8296],\n",
            "        [-0.8209, -0.9302, -0.4691,  ..., -0.2064, -1.3451, -0.8706],\n",
            "        [-0.8304, -0.9243, -0.4787,  ...,  0.5520, -1.7997, -1.5844],\n",
            "        ...,\n",
            "        [-0.8284, -0.9255, -0.4769,  ...,  0.4026, -1.7003, -1.4492],\n",
            "        [-0.8230, -0.9286, -0.4712,  ..., -0.0384, -1.4307, -1.1184],\n",
            "        [-0.8304, -0.9233, -0.4807,  ...,  0.6395, -1.8212, -1.7817]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0822, -0.0928, -0.0470,  ..., -0.0061, -0.1415, -0.1082],\n",
            "        [-0.0825, -0.0928, -0.0474,  ...,  0.0244, -0.1575, -0.1247],\n",
            "        [-0.0823, -0.0928, -0.0471,  ..., -0.0024, -0.1434, -0.1070],\n",
            "        ...,\n",
            "        [-0.0819, -0.0933, -0.0470,  ...,  0.0014, -0.1333, -0.0984],\n",
            "        [-0.0820, -0.0940, -0.0463,  ...,  0.0138, -0.1351, -0.0122],\n",
            "        [-0.0828, -0.0926, -0.0475,  ...,  0.0324, -0.1706, -0.1430]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8222, -0.9283, -0.4702,  ..., -0.0615, -1.4149, -1.0816],\n",
            "        [-0.8250, -0.9278, -0.4740,  ...,  0.2441, -1.5751, -1.2469],\n",
            "        [-0.8231, -0.9277, -0.4709,  ..., -0.0237, -1.4335, -1.0696],\n",
            "        ...,\n",
            "        [-0.8187, -0.9325, -0.4696,  ...,  0.0137, -1.3332, -0.9844],\n",
            "        [-0.8197, -0.9399, -0.4634,  ...,  0.1384, -1.3506, -0.1216],\n",
            "        [-0.8284, -0.9258, -0.4749,  ...,  0.3241, -1.7064, -1.4295]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0824, -0.0928, -0.0473,  ...,  0.0184, -0.1537, -0.1213],\n",
            "        [-0.0821, -0.0928, -0.0470,  ..., -0.0032, -0.1391, -0.1015],\n",
            "        [-0.0827, -0.0924, -0.0476,  ...,  0.0391, -0.1671, -0.1478],\n",
            "        ...,\n",
            "        [-0.0820, -0.0931, -0.0470,  ...,  0.0012, -0.1366, -0.1108],\n",
            "        [-0.0821, -0.0929, -0.0468,  ..., -0.0051, -0.1405, -0.1052],\n",
            "        [-0.0829, -0.0922, -0.0477,  ...,  0.0494, -0.1774, -0.1614]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8240, -0.9284, -0.4728,  ...,  0.1839, -1.5368, -1.2129],\n",
            "        [-0.8212, -0.9278, -0.4698,  ..., -0.0322, -1.3913, -1.0155],\n",
            "        [-0.8271, -0.9240, -0.4764,  ...,  0.3910, -1.6709, -1.4777],\n",
            "        ...,\n",
            "        [-0.8196, -0.9309, -0.4704,  ...,  0.0117, -1.3661, -1.1083],\n",
            "        [-0.8207, -0.9288, -0.4681,  ..., -0.0506, -1.4051, -1.0520],\n",
            "        [-0.8294, -0.9224, -0.4771,  ...,  0.4938, -1.7736, -1.6139]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0823, -0.0926, -0.0472,  ...,  0.0202, -0.1532, -0.1317],\n",
            "        [-0.0818, -0.0937, -0.0462,  ...,  0.0098, -0.1329, -0.0257],\n",
            "        [-0.0822, -0.0927, -0.0472,  ...,  0.0182, -0.1514, -0.1166],\n",
            "        ...,\n",
            "        [-0.0825, -0.0926, -0.0475,  ...,  0.0357, -0.1639, -0.1351],\n",
            "        [-0.0819, -0.0937, -0.0462,  ...,  0.0090, -0.1348, -0.0237],\n",
            "        [-0.0818, -0.0934, -0.0463,  ...,  0.0050, -0.1330, -0.0354]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8229, -0.9257, -0.4718,  ...,  0.2018, -1.5322, -1.3170],\n",
            "        [-0.8177, -0.9367, -0.4616,  ...,  0.0985, -1.3285, -0.2572],\n",
            "        [-0.8223, -0.9273, -0.4721,  ...,  0.1821, -1.5136, -1.1656],\n",
            "        ...,\n",
            "        [-0.8248, -0.9256, -0.4747,  ...,  0.3568, -1.6392, -1.3509],\n",
            "        [-0.8188, -0.9374, -0.4624,  ...,  0.0899, -1.3482, -0.2369],\n",
            "        [-0.8183, -0.9341, -0.4634,  ...,  0.0499, -1.3297, -0.3541]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0820, -0.0927, -0.0468,  ...,  0.0032, -0.1418, -0.0992],\n",
            "        [-0.0817, -0.0929, -0.0464,  ..., -0.0249, -0.1267, -0.0885],\n",
            "        [-0.0819, -0.0928, -0.0468,  ...,  0.0034, -0.1383, -0.1093],\n",
            "        ...,\n",
            "        [-0.0817, -0.0935, -0.0462,  ...,  0.0065, -0.1319, -0.0311],\n",
            "        [-0.0816, -0.0935, -0.0462,  ...,  0.0033, -0.1268, -0.0397],\n",
            "        [-0.0821, -0.0933, -0.0465,  ...,  0.0265, -0.1517, -0.0364]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8200, -0.9273, -0.4681,  ...,  0.0325, -1.4178, -0.9916],\n",
            "        [-0.8165, -0.9287, -0.4645,  ..., -0.2486, -1.2670, -0.8850],\n",
            "        [-0.8187, -0.9279, -0.4680,  ...,  0.0338, -1.3827, -1.0925],\n",
            "        ...,\n",
            "        [-0.8174, -0.9354, -0.4615,  ...,  0.0654, -1.3189, -0.3112],\n",
            "        [-0.8155, -0.9349, -0.4616,  ...,  0.0334, -1.2678, -0.3972],\n",
            "        [-0.8213, -0.9332, -0.4654,  ...,  0.2648, -1.5174, -0.3639]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0822, -0.0926, -0.0470,  ...,  0.0168, -0.1517, -0.1207],\n",
            "        [-0.0817, -0.0927, -0.0462,  ..., -0.0297, -0.1321, -0.0938],\n",
            "        [-0.0820, -0.0926, -0.0467,  ..., -0.0014, -0.1396, -0.1106],\n",
            "        ...,\n",
            "        [-0.0822, -0.0923, -0.0470,  ...,  0.0237, -0.1560, -0.1278],\n",
            "        [-0.0816, -0.0934, -0.0460,  ..., -0.0021, -0.1280, -0.0355],\n",
            "        [-0.0814, -0.0930, -0.0463,  ..., -0.0175, -0.1249, -0.0820]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8215, -0.9259, -0.4697,  ...,  0.1682, -1.5168, -1.2072],\n",
            "        [-0.8165, -0.9269, -0.4618,  ..., -0.2966, -1.3210, -0.9376],\n",
            "        [-0.8195, -0.9256, -0.4674,  ..., -0.0141, -1.3959, -1.1056],\n",
            "        ...,\n",
            "        [-0.8224, -0.9232, -0.4699,  ...,  0.2372, -1.5599, -1.2782],\n",
            "        [-0.8157, -0.9339, -0.4602,  ..., -0.0214, -1.2803, -0.3547],\n",
            "        [-0.8139, -0.9305, -0.4635,  ..., -0.1753, -1.2487, -0.8201]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0824, -0.0923, -0.0473,  ...,  0.0348, -0.1628, -0.1410],\n",
            "        [-0.0818, -0.0926, -0.0464,  ..., -0.0217, -0.1325, -0.0859],\n",
            "        [-0.0816, -0.0934, -0.0461,  ...,  0.0029, -0.1301, -0.0382],\n",
            "        ...,\n",
            "        [-0.0818, -0.0935, -0.0460,  ...,  0.0065, -0.1374, -0.0298],\n",
            "        [-0.0816, -0.0926, -0.0461,  ..., -0.0344, -0.1245, -0.0928],\n",
            "        [-0.0816, -0.0933, -0.0461,  ...,  0.0018, -0.1290, -0.0415]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8240, -0.9228, -0.4727,  ...,  0.3477, -1.6278, -1.4102],\n",
            "        [-0.8177, -0.9258, -0.4645,  ..., -0.2167, -1.3253, -0.8591],\n",
            "        [-0.8157, -0.9335, -0.4607,  ...,  0.0290, -1.3007, -0.3821],\n",
            "        ...,\n",
            "        [-0.8177, -0.9345, -0.4598,  ...,  0.0651, -1.3744, -0.2982],\n",
            "        [-0.8156, -0.9259, -0.4611,  ..., -0.3440, -1.2447, -0.9276],\n",
            "        [-0.8160, -0.9327, -0.4607,  ...,  0.0179, -1.2895, -0.4155]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0827, -0.0920, -0.0471,  ...,  0.0352, -0.1703, -0.1444],\n",
            "        [-0.0817, -0.0925, -0.0461,  ..., -0.0287, -0.1267, -0.0903],\n",
            "        [-0.0816, -0.0932, -0.0458,  ...,  0.0026, -0.1301, -0.0343],\n",
            "        ...,\n",
            "        [-0.0822, -0.0924, -0.0468,  ...,  0.0153, -0.1499, -0.1157],\n",
            "        [-0.0818, -0.0933, -0.0458,  ...,  0.0046, -0.1362, -0.0253],\n",
            "        [-0.0826, -0.0921, -0.0469,  ...,  0.0315, -0.1686, -0.1419]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8268, -0.9204, -0.4708,  ...,  0.3517, -1.7031, -1.4436],\n",
            "        [-0.8171, -0.9253, -0.4614,  ..., -0.2866, -1.2667, -0.9034],\n",
            "        [-0.8164, -0.9322, -0.4577,  ...,  0.0256, -1.3008, -0.3429],\n",
            "        ...,\n",
            "        [-0.8221, -0.9242, -0.4685,  ...,  0.1526, -1.4985, -1.1575],\n",
            "        [-0.8184, -0.9329, -0.4582,  ...,  0.0458, -1.3622, -0.2534],\n",
            "        [-0.8259, -0.9205, -0.4693,  ...,  0.3145, -1.6855, -1.4187]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0820, -0.0925, -0.0464,  ..., -0.0014, -0.1377, -0.1113],\n",
            "        [-0.0819, -0.0925, -0.0464,  ..., -0.0004, -0.1349, -0.1079],\n",
            "        [-0.0820, -0.0924, -0.0464,  ..., -0.0016, -0.1391, -0.1071],\n",
            "        ...,\n",
            "        [-0.0821, -0.0924, -0.0463,  ..., -0.0036, -0.1414, -0.1050],\n",
            "        [-0.0818, -0.0930, -0.0458,  ...,  0.0011, -0.1319, -0.0421],\n",
            "        [-0.0821, -0.0923, -0.0463,  ..., -0.0070, -0.1444, -0.1041]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8195, -0.9248, -0.4638,  ..., -0.0136, -1.3775, -1.1133],\n",
            "        [-0.8189, -0.9254, -0.4640,  ..., -0.0037, -1.3493, -1.0788],\n",
            "        [-0.8201, -0.9245, -0.4642,  ..., -0.0163, -1.3908, -1.0707],\n",
            "        ...,\n",
            "        [-0.8207, -0.9243, -0.4634,  ..., -0.0357, -1.4137, -1.0501],\n",
            "        [-0.8179, -0.9302, -0.4578,  ...,  0.0106, -1.3191, -0.4212],\n",
            "        [-0.8214, -0.9225, -0.4627,  ..., -0.0702, -1.4444, -1.0414]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-8.2602e-02, -9.1931e-02, -4.6855e-02,  ...,  3.6634e-02,\n",
            "         -1.6262e-01, -1.4166e-01],\n",
            "        [-8.2488e-02, -9.1976e-02, -4.6392e-02,  ...,  1.2089e-02,\n",
            "         -1.5616e-01, -1.2604e-01],\n",
            "        [-8.2016e-02, -9.2285e-02, -4.6046e-02,  ..., -6.7890e-03,\n",
            "         -1.3850e-01, -9.9535e-02],\n",
            "        ...,\n",
            "        [-8.2305e-02, -9.2135e-02, -4.6501e-02,  ...,  1.5035e-02,\n",
            "         -1.4861e-01, -1.2558e-01],\n",
            "        [-8.2580e-02, -9.2020e-02, -4.6522e-02,  ...,  1.5436e-02,\n",
            "         -1.5834e-01, -1.2803e-01],\n",
            "        [-8.1869e-02, -9.2536e-02, -4.6244e-02,  ..., -6.6251e-05,\n",
            "         -1.3020e-01, -1.0271e-01]], grad_fn=<CatBackward0>)\n",
            "New tensor([[-8.2602e-01, -9.1931e-01, -4.6855e-01,  ...,  3.6634e-01,\n",
            "         -1.6262e+00, -1.4166e+00],\n",
            "        [-8.2488e-01, -9.1976e-01, -4.6392e-01,  ...,  1.2089e-01,\n",
            "         -1.5616e+00, -1.2604e+00],\n",
            "        [-8.2016e-01, -9.2285e-01, -4.6046e-01,  ..., -6.7890e-02,\n",
            "         -1.3850e+00, -9.9535e-01],\n",
            "        ...,\n",
            "        [-8.2305e-01, -9.2135e-01, -4.6501e-01,  ...,  1.5035e-01,\n",
            "         -1.4861e+00, -1.2558e+00],\n",
            "        [-8.2580e-01, -9.2020e-01, -4.6522e-01,  ...,  1.5436e-01,\n",
            "         -1.5834e+00, -1.2803e+00],\n",
            "        [-8.1869e-01, -9.2536e-01, -4.6244e-01,  ..., -6.6251e-04,\n",
            "         -1.3020e+00, -1.0271e+00]], grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0822, -0.0921, -0.0464,  ...,  0.0123, -0.1485, -0.1215],\n",
            "        [-0.0824, -0.0920, -0.0465,  ...,  0.0167, -0.1526, -0.1271],\n",
            "        [-0.0820, -0.0922, -0.0463,  ...,  0.0013, -0.1393, -0.1138],\n",
            "        ...,\n",
            "        [-0.0818, -0.0929, -0.0455,  ..., -0.0035, -0.1297, -0.0409],\n",
            "        [-0.0819, -0.0930, -0.0456,  ...,  0.0049, -0.1351, -0.0329],\n",
            "        [-0.0818, -0.0931, -0.0454,  ...,  0.0043, -0.1307, -0.0258]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8219, -0.9211, -0.4641,  ...,  0.1230, -1.4852, -1.2153],\n",
            "        [-0.8237, -0.9199, -0.4652,  ...,  0.1666, -1.5261, -1.2713],\n",
            "        [-0.8204, -0.9218, -0.4625,  ...,  0.0125, -1.3931, -1.1382],\n",
            "        ...,\n",
            "        [-0.8180, -0.9286, -0.4548,  ..., -0.0346, -1.2974, -0.4087],\n",
            "        [-0.8192, -0.9299, -0.4565,  ...,  0.0494, -1.3514, -0.3287],\n",
            "        [-0.8180, -0.9310, -0.4543,  ...,  0.0434, -1.3070, -0.2575]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0816, -0.0924, -0.0462,  ..., -0.0028, -0.1362, -0.1012],\n",
            "        [-0.0822, -0.0920, -0.0464,  ...,  0.0137, -0.1591, -0.1242],\n",
            "        [-0.0821, -0.0921, -0.0466,  ...,  0.0189, -0.1550, -0.1125],\n",
            "        ...,\n",
            "        [-0.0815, -0.0932, -0.0455,  ...,  0.0041, -0.1296, -0.0308],\n",
            "        [-0.0826, -0.0916, -0.0472,  ...,  0.0570, -0.1780, -0.1654],\n",
            "        [-0.0817, -0.0924, -0.0463,  ...,  0.0010, -0.1378, -0.1013]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8164, -0.9245, -0.4623,  ..., -0.0276, -1.3621, -1.0115],\n",
            "        [-0.8224, -0.9202, -0.4644,  ...,  0.1371, -1.5905, -1.2417],\n",
            "        [-0.8215, -0.9208, -0.4657,  ...,  0.1894, -1.5503, -1.1247],\n",
            "        ...,\n",
            "        [-0.8150, -0.9316, -0.4549,  ...,  0.0409, -1.2963, -0.3085],\n",
            "        [-0.8262, -0.9160, -0.4716,  ...,  0.5701, -1.7796, -1.6535],\n",
            "        [-0.8168, -0.9242, -0.4628,  ...,  0.0105, -1.3780, -1.0127]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0825, -0.0917, -0.0471,  ...,  0.0533, -0.1803, -0.1558],\n",
            "        [-0.0822, -0.0918, -0.0469,  ...,  0.0362, -0.1667, -0.1360],\n",
            "        [-0.0816, -0.0923, -0.0464,  ...,  0.0011, -0.1400, -0.1125],\n",
            "        ...,\n",
            "        [-0.0819, -0.0920, -0.0465,  ...,  0.0197, -0.1577, -0.1213],\n",
            "        [-0.0816, -0.0922, -0.0461,  ..., -0.0047, -0.1411, -0.1052],\n",
            "        [-0.0816, -0.0922, -0.0461,  ..., -0.0042, -0.1463, -0.1037]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8248, -0.9169, -0.4706,  ...,  0.5331, -1.8026, -1.5578],\n",
            "        [-0.8221, -0.9183, -0.4688,  ...,  0.3621, -1.6674, -1.3602],\n",
            "        [-0.8162, -0.9226, -0.4637,  ...,  0.0113, -1.3999, -1.1246],\n",
            "        ...,\n",
            "        [-0.8195, -0.9196, -0.4649,  ...,  0.1973, -1.5774, -1.2135],\n",
            "        [-0.8164, -0.9216, -0.4615,  ..., -0.0466, -1.4108, -1.0521],\n",
            "        [-0.8165, -0.9218, -0.4612,  ..., -0.0421, -1.4627, -1.0368]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-8.1204e-02, -9.3018e-02, -4.5630e-02,  ...,  3.0287e-03,\n",
            "         -1.3174e-01, -3.8976e-02],\n",
            "        [-8.1593e-02, -9.2143e-02, -4.6142e-02,  ...,  1.5499e-04,\n",
            "         -1.4542e-01, -1.0477e-01],\n",
            "        [-8.2043e-02, -9.1826e-02, -4.6922e-02,  ...,  3.6815e-02,\n",
            "         -1.6382e-01, -1.4425e-01],\n",
            "        ...,\n",
            "        [-8.2046e-02, -9.1888e-02, -4.6790e-02,  ...,  3.8228e-02,\n",
            "         -1.6643e-01, -1.4441e-01],\n",
            "        [-8.1834e-02, -9.2145e-02, -4.6623e-02,  ...,  1.8856e-02,\n",
            "         -1.5435e-01, -1.2163e-01],\n",
            "        [-8.1804e-02, -9.1916e-02, -4.6507e-02,  ...,  2.2922e-02,\n",
            "         -1.5740e-01, -1.2221e-01]], grad_fn=<CatBackward0>)\n",
            "New tensor([[-8.1204e-01, -9.3018e-01, -4.5630e-01,  ...,  3.0287e-02,\n",
            "         -1.3174e+00, -3.8976e-01],\n",
            "        [-8.1593e-01, -9.2143e-01, -4.6142e-01,  ...,  1.5499e-03,\n",
            "         -1.4542e+00, -1.0477e+00],\n",
            "        [-8.2043e-01, -9.1826e-01, -4.6922e-01,  ...,  3.6815e-01,\n",
            "         -1.6382e+00, -1.4425e+00],\n",
            "        ...,\n",
            "        [-8.2046e-01, -9.1888e-01, -4.6790e-01,  ...,  3.8228e-01,\n",
            "         -1.6643e+00, -1.4441e+00],\n",
            "        [-8.1834e-01, -9.2145e-01, -4.6623e-01,  ...,  1.8856e-01,\n",
            "         -1.5435e+00, -1.2163e+00],\n",
            "        [-8.1804e-01, -9.1916e-01, -4.6507e-01,  ...,  2.2922e-01,\n",
            "         -1.5740e+00, -1.2221e+00]], grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0817, -0.0922, -0.0464,  ...,  0.0144, -0.1507, -0.1146],\n",
            "        [-0.0821, -0.0918, -0.0467,  ...,  0.0394, -0.1661, -0.1439],\n",
            "        [-0.0816, -0.0921, -0.0461,  ..., -0.0026, -0.1433, -0.1053],\n",
            "        ...,\n",
            "        [-0.0817, -0.0920, -0.0464,  ...,  0.0222, -0.1544, -0.1231],\n",
            "        [-0.0820, -0.0918, -0.0467,  ...,  0.0366, -0.1633, -0.1442],\n",
            "        [-0.0816, -0.0921, -0.0463,  ..., -0.0015, -0.1429, -0.1011]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8174, -0.9217, -0.4639,  ...,  0.1444, -1.5073, -1.1465],\n",
            "        [-0.8206, -0.9183, -0.4674,  ...,  0.3943, -1.6612, -1.4395],\n",
            "        [-0.8159, -0.9207, -0.4607,  ..., -0.0263, -1.4327, -1.0528],\n",
            "        ...,\n",
            "        [-0.8175, -0.9204, -0.4641,  ...,  0.2216, -1.5443, -1.2313],\n",
            "        [-0.8203, -0.9182, -0.4675,  ...,  0.3656, -1.6327, -1.4421],\n",
            "        [-0.8164, -0.9212, -0.4627,  ..., -0.0152, -1.4291, -1.0106]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0817, -0.0922, -0.0463,  ...,  0.0146, -0.1456, -0.1043],\n",
            "        [-0.0814, -0.0924, -0.0461,  ...,  0.0016, -0.1313, -0.0985],\n",
            "        [-0.0820, -0.0917, -0.0463,  ...,  0.0259, -0.1583, -0.1238],\n",
            "        ...,\n",
            "        [-0.0818, -0.0921, -0.0464,  ...,  0.0232, -0.1499, -0.1242],\n",
            "        [-0.0815, -0.0931, -0.0455,  ...,  0.0089, -0.1346, -0.0255],\n",
            "        [-0.0818, -0.0921, -0.0461,  ..., -0.0028, -0.1430, -0.0947]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8174, -0.9216, -0.4630,  ...,  0.1462, -1.4561, -1.0428],\n",
            "        [-0.8141, -0.9243, -0.4609,  ...,  0.0156, -1.3129, -0.9853],\n",
            "        [-0.8201, -0.9169, -0.4635,  ...,  0.2588, -1.5833, -1.2384],\n",
            "        ...,\n",
            "        [-0.8185, -0.9208, -0.4643,  ...,  0.2322, -1.4992, -1.2418],\n",
            "        [-0.8151, -0.9312, -0.4546,  ...,  0.0889, -1.3458, -0.2554],\n",
            "        [-0.8176, -0.9210, -0.4610,  ..., -0.0285, -1.4298, -0.9475]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0820, -0.0920, -0.0463,  ...,  0.0189, -0.1528, -0.1159],\n",
            "        [-0.0822, -0.0918, -0.0464,  ...,  0.0204, -0.1585, -0.1268],\n",
            "        [-0.0823, -0.0916, -0.0466,  ...,  0.0385, -0.1685, -0.1383],\n",
            "        ...,\n",
            "        [-0.0817, -0.0929, -0.0457,  ...,  0.0239, -0.1457, -0.0406],\n",
            "        [-0.0816, -0.0923, -0.0460,  ...,  0.0031, -0.1374, -0.1008],\n",
            "        [-0.0821, -0.0918, -0.0464,  ...,  0.0187, -0.1571, -0.1276]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8196, -0.9198, -0.4628,  ...,  0.1888, -1.5282, -1.1587],\n",
            "        [-0.8219, -0.9182, -0.4645,  ...,  0.2044, -1.5847, -1.2676],\n",
            "        [-0.8233, -0.9164, -0.4657,  ...,  0.3853, -1.6845, -1.3828],\n",
            "        ...,\n",
            "        [-0.8174, -0.9285, -0.4573,  ...,  0.2395, -1.4573, -0.4065],\n",
            "        [-0.8160, -0.9227, -0.4604,  ...,  0.0312, -1.3739, -1.0076],\n",
            "        [-0.8212, -0.9180, -0.4641,  ...,  0.1866, -1.5712, -1.2755]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0814, -0.0922, -0.0457,  ..., -0.0216, -0.1291, -0.0857],\n",
            "        [-0.0815, -0.0923, -0.0459,  ..., -0.0008, -0.1330, -0.0983],\n",
            "        [-0.0814, -0.0923, -0.0457,  ..., -0.0247, -0.1267, -0.0893],\n",
            "        ...,\n",
            "        [-0.0812, -0.0925, -0.0456,  ..., -0.0248, -0.1176, -0.0874],\n",
            "        [-0.0822, -0.0918, -0.0464,  ...,  0.0170, -0.1553, -0.1215],\n",
            "        [-0.0816, -0.0930, -0.0454,  ...,  0.0068, -0.1348, -0.0336]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8144, -0.9224, -0.4571,  ..., -0.2165, -1.2911, -0.8573],\n",
            "        [-0.8152, -0.9229, -0.4592,  ..., -0.0083, -1.3304, -0.9825],\n",
            "        [-0.8143, -0.9226, -0.4566,  ..., -0.2468, -1.2675, -0.8928],\n",
            "        ...,\n",
            "        [-0.8117, -0.9247, -0.4557,  ..., -0.2482, -1.1765, -0.8741],\n",
            "        [-0.8217, -0.9180, -0.4639,  ...,  0.1702, -1.5534, -1.2153],\n",
            "        [-0.8159, -0.9300, -0.4538,  ...,  0.0685, -1.3476, -0.3360]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0823, -0.0917, -0.0466,  ...,  0.0361, -0.1657, -0.1330],\n",
            "        [-0.0818, -0.0920, -0.0461,  ..., -0.0013, -0.1451, -0.1041],\n",
            "        [-0.0820, -0.0919, -0.0462,  ...,  0.0161, -0.1541, -0.1111],\n",
            "        ...,\n",
            "        [-0.0820, -0.0919, -0.0462,  ...,  0.0147, -0.1547, -0.1129],\n",
            "        [-0.0817, -0.0920, -0.0460,  ..., -0.0034, -0.1385, -0.1013],\n",
            "        [-0.0816, -0.0922, -0.0460,  ...,  0.0022, -0.1367, -0.1096]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8228, -0.9169, -0.4664,  ...,  0.3606, -1.6574, -1.3301],\n",
            "        [-0.8184, -0.9204, -0.4607,  ..., -0.0132, -1.4513, -1.0408],\n",
            "        [-0.8200, -0.9188, -0.4621,  ...,  0.1608, -1.5412, -1.1109],\n",
            "        ...,\n",
            "        [-0.8199, -0.9187, -0.4621,  ...,  0.1472, -1.5473, -1.1287],\n",
            "        [-0.8165, -0.9196, -0.4601,  ..., -0.0336, -1.3853, -1.0127],\n",
            "        [-0.8156, -0.9216, -0.4601,  ...,  0.0217, -1.3669, -1.0961]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0822, -0.0916, -0.0466,  ...,  0.0387, -0.1713, -0.1369],\n",
            "        [-0.0820, -0.0919, -0.0464,  ...,  0.0168, -0.1578, -0.1233],\n",
            "        [-0.0812, -0.0924, -0.0458,  ..., -0.0186, -0.1277, -0.0856],\n",
            "        ...,\n",
            "        [-0.0814, -0.0921, -0.0460,  ...,  0.0005, -0.1395, -0.1042],\n",
            "        [-0.0820, -0.0919, -0.0468,  ...,  0.0365, -0.1600, -0.1370],\n",
            "        [-0.0814, -0.0926, -0.0458,  ...,  0.0184, -0.1381, -0.0570]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8218, -0.9163, -0.4660,  ...,  0.3872, -1.7131, -1.3687],\n",
            "        [-0.8201, -0.9188, -0.4644,  ...,  0.1683, -1.5784, -1.2335],\n",
            "        [-0.8115, -0.9236, -0.4582,  ..., -0.1858, -1.2773, -0.8562],\n",
            "        ...,\n",
            "        [-0.8138, -0.9212, -0.4596,  ...,  0.0051, -1.3947, -1.0417],\n",
            "        [-0.8203, -0.9185, -0.4677,  ...,  0.3646, -1.5997, -1.3701],\n",
            "        [-0.8145, -0.9260, -0.4582,  ...,  0.1837, -1.3806, -0.5703]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0818, -0.0920, -0.0466,  ...,  0.0208, -0.1495, -0.1188],\n",
            "        [-0.0823, -0.0917, -0.0468,  ...,  0.0358, -0.1683, -0.1312],\n",
            "        [-0.0819, -0.0920, -0.0466,  ...,  0.0197, -0.1540, -0.1227],\n",
            "        ...,\n",
            "        [-0.0819, -0.0919, -0.0466,  ...,  0.0169, -0.1525, -0.1169],\n",
            "        [-0.0824, -0.0915, -0.0471,  ...,  0.0549, -0.1755, -0.1559],\n",
            "        [-0.0816, -0.0920, -0.0461,  ..., -0.0013, -0.1393, -0.1145]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8183, -0.9198, -0.4661,  ...,  0.2080, -1.4950, -1.1877],\n",
            "        [-0.8226, -0.9175, -0.4678,  ...,  0.3582, -1.6829, -1.3121],\n",
            "        [-0.8191, -0.9199, -0.4661,  ...,  0.1969, -1.5399, -1.2274],\n",
            "        ...,\n",
            "        [-0.8193, -0.9185, -0.4657,  ...,  0.1691, -1.5250, -1.1695],\n",
            "        [-0.8240, -0.9151, -0.4709,  ...,  0.5486, -1.7553, -1.5594],\n",
            "        [-0.8159, -0.9201, -0.4615,  ..., -0.0135, -1.3931, -1.1447]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0815, -0.0920, -0.0461,  ..., -0.0093, -0.1376, -0.0975],\n",
            "        [-0.0819, -0.0919, -0.0465,  ...,  0.0183, -0.1539, -0.1209],\n",
            "        [-0.0819, -0.0925, -0.0462,  ...,  0.0364, -0.1521, -0.0586],\n",
            "        ...,\n",
            "        [-0.0815, -0.0921, -0.0461,  ..., -0.0214, -0.1339, -0.0868],\n",
            "        [-0.0823, -0.0916, -0.0470,  ...,  0.0514, -0.1742, -0.1569],\n",
            "        [-0.0819, -0.0918, -0.0465,  ...,  0.0180, -0.1527, -0.1196]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8152, -0.9202, -0.4610,  ..., -0.0928, -1.3756, -0.9746],\n",
            "        [-0.8193, -0.9186, -0.4651,  ...,  0.1828, -1.5386, -1.2090],\n",
            "        [-0.8185, -0.9251, -0.4618,  ...,  0.3644, -1.5209, -0.5863],\n",
            "        ...,\n",
            "        [-0.8149, -0.9212, -0.4607,  ..., -0.2137, -1.3390, -0.8680],\n",
            "        [-0.8234, -0.9157, -0.4699,  ...,  0.5136, -1.7416, -1.5690],\n",
            "        [-0.8191, -0.9183, -0.4653,  ...,  0.1801, -1.5267, -1.1956]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0820, -0.0920, -0.0466,  ...,  0.0161, -0.1507, -0.1202],\n",
            "        [-0.0818, -0.0920, -0.0462,  ..., -0.0020, -0.1440, -0.0962],\n",
            "        [-0.0815, -0.0929, -0.0455,  ...,  0.0015, -0.1301, -0.0298],\n",
            "        ...,\n",
            "        [-0.0820, -0.0918, -0.0463,  ...,  0.0089, -0.1518, -0.1206],\n",
            "        [-0.0822, -0.0918, -0.0468,  ...,  0.0318, -0.1594, -0.1292],\n",
            "        [-0.0818, -0.0920, -0.0464,  ...,  0.0194, -0.1469, -0.1199]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8199, -0.9197, -0.4656,  ...,  0.1609, -1.5065, -1.2017],\n",
            "        [-0.8181, -0.9197, -0.4623,  ..., -0.0201, -1.4402, -0.9620],\n",
            "        [-0.8149, -0.9289, -0.4549,  ...,  0.0153, -1.3007, -0.2984],\n",
            "        ...,\n",
            "        [-0.8198, -0.9183, -0.4635,  ...,  0.0891, -1.5179, -1.2064],\n",
            "        [-0.8217, -0.9176, -0.4677,  ...,  0.3180, -1.5940, -1.2917],\n",
            "        [-0.8178, -0.9199, -0.4640,  ...,  0.1942, -1.4694, -1.1986]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0812, -0.0926, -0.0459,  ..., -0.0189, -0.1192, -0.0871],\n",
            "        [-0.0818, -0.0920, -0.0461,  ..., -0.0010, -0.1408, -0.1048],\n",
            "        [-0.0821, -0.0918, -0.0466,  ...,  0.0152, -0.1509, -0.1247],\n",
            "        ...,\n",
            "        [-0.0825, -0.0915, -0.0469,  ...,  0.0456, -0.1701, -0.1473],\n",
            "        [-0.0815, -0.0924, -0.0463,  ...,  0.0030, -0.1331, -0.1019],\n",
            "        [-0.0824, -0.0916, -0.0467,  ...,  0.0354, -0.1674, -0.1389]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8119, -0.9258, -0.4588,  ..., -0.1890, -1.1924, -0.8713],\n",
            "        [-0.8176, -0.9200, -0.4608,  ..., -0.0096, -1.4082, -1.0483],\n",
            "        [-0.8210, -0.9178, -0.4659,  ...,  0.1524, -1.5089, -1.2466],\n",
            "        ...,\n",
            "        [-0.8248, -0.9154, -0.4691,  ...,  0.4555, -1.7009, -1.4733],\n",
            "        [-0.8153, -0.9236, -0.4625,  ...,  0.0301, -1.3313, -1.0191],\n",
            "        [-0.8237, -0.9157, -0.4674,  ...,  0.3540, -1.6743, -1.3888]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0820, -0.0919, -0.0462,  ..., -0.0045, -0.1435, -0.1004],\n",
            "        [-0.0822, -0.0917, -0.0465,  ...,  0.0184, -0.1542, -0.1150],\n",
            "        [-0.0827, -0.0915, -0.0470,  ...,  0.0469, -0.1722, -0.1446],\n",
            "        ...,\n",
            "        [-0.0817, -0.0921, -0.0462,  ..., -0.0040, -0.1324, -0.1071],\n",
            "        [-0.0820, -0.0919, -0.0463,  ...,  0.0152, -0.1484, -0.1172],\n",
            "        [-0.0823, -0.0917, -0.0466,  ...,  0.0192, -0.1553, -0.1212]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8196, -0.9195, -0.4620,  ..., -0.0450, -1.4348, -1.0041],\n",
            "        [-0.8220, -0.9169, -0.4645,  ...,  0.1836, -1.5420, -1.1504],\n",
            "        [-0.8266, -0.9153, -0.4696,  ...,  0.4689, -1.7225, -1.4462],\n",
            "        ...,\n",
            "        [-0.8175, -0.9209, -0.4621,  ..., -0.0403, -1.3240, -1.0711],\n",
            "        [-0.8199, -0.9191, -0.4635,  ...,  0.1519, -1.4842, -1.1720],\n",
            "        [-0.8228, -0.9172, -0.4659,  ...,  0.1917, -1.5533, -1.2120]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0815, -0.0926, -0.0462,  ..., -0.0002, -0.1267, -0.0993],\n",
            "        [-0.0817, -0.0921, -0.0460,  ..., -0.0234, -0.1277, -0.0870],\n",
            "        [-0.0817, -0.0928, -0.0456,  ...,  0.0036, -0.1316, -0.0339],\n",
            "        ...,\n",
            "        [-0.0822, -0.0918, -0.0465,  ...,  0.0121, -0.1524, -0.1140],\n",
            "        [-0.0825, -0.0916, -0.0469,  ...,  0.0327, -0.1611, -0.1413],\n",
            "        [-0.0816, -0.0927, -0.0456,  ..., -0.0014, -0.1258, -0.0368]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8149, -0.9261, -0.4617,  ..., -0.0021, -1.2669, -0.9930],\n",
            "        [-0.8170, -0.9208, -0.4603,  ..., -0.2338, -1.2767, -0.8696],\n",
            "        [-0.8171, -0.9280, -0.4561,  ...,  0.0358, -1.3156, -0.3393],\n",
            "        ...,\n",
            "        [-0.8224, -0.9183, -0.4645,  ...,  0.1211, -1.5243, -1.1402],\n",
            "        [-0.8245, -0.9157, -0.4689,  ...,  0.3267, -1.6107, -1.4133],\n",
            "        [-0.8159, -0.9270, -0.4559,  ..., -0.0145, -1.2584, -0.3678]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0824, -0.0916, -0.0468,  ...,  0.0306, -0.1618, -0.1388],\n",
            "        [-0.0820, -0.0918, -0.0464,  ...,  0.0018, -0.1449, -0.1126],\n",
            "        [-0.0818, -0.0921, -0.0463,  ..., -0.0033, -0.1368, -0.0987],\n",
            "        ...,\n",
            "        [-0.0820, -0.0919, -0.0462,  ..., -0.0044, -0.1486, -0.1112],\n",
            "        [-0.0822, -0.0917, -0.0466,  ...,  0.0152, -0.1522, -0.1298],\n",
            "        [-0.0815, -0.0927, -0.0456,  ..., -0.0079, -0.1233, -0.0441]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8238, -0.9163, -0.4684,  ...,  0.3059, -1.6181, -1.3877],\n",
            "        [-0.8197, -0.9180, -0.4639,  ...,  0.0182, -1.4490, -1.1258],\n",
            "        [-0.8176, -0.9208, -0.4631,  ..., -0.0326, -1.3684, -0.9873],\n",
            "        ...,\n",
            "        [-0.8203, -0.9191, -0.4619,  ..., -0.0437, -1.4864, -1.1120],\n",
            "        [-0.8217, -0.9171, -0.4664,  ...,  0.1519, -1.5220, -1.2983],\n",
            "        [-0.8152, -0.9268, -0.4557,  ..., -0.0795, -1.2334, -0.4412]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0816, -0.0921, -0.0462,  ..., -0.0089, -0.1343, -0.0971],\n",
            "        [-0.0818, -0.0920, -0.0464,  ..., -0.0058, -0.1391, -0.0964],\n",
            "        [-0.0823, -0.0917, -0.0469,  ...,  0.0322, -0.1618, -0.1269],\n",
            "        ...,\n",
            "        [-0.0817, -0.0921, -0.0463,  ..., -0.0011, -0.1398, -0.0965],\n",
            "        [-0.0821, -0.0918, -0.0466,  ...,  0.0146, -0.1524, -0.1149],\n",
            "        [-0.0820, -0.0920, -0.0466,  ...,  0.0159, -0.1494, -0.1231]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8162, -0.9211, -0.4623,  ..., -0.0886, -1.3432, -0.9713],\n",
            "        [-0.8179, -0.9195, -0.4636,  ..., -0.0579, -1.3913, -0.9636],\n",
            "        [-0.8229, -0.9173, -0.4686,  ...,  0.3222, -1.6176, -1.2692],\n",
            "        ...,\n",
            "        [-0.8173, -0.9208, -0.4634,  ..., -0.0106, -1.3977, -0.9649],\n",
            "        [-0.8209, -0.9177, -0.4657,  ...,  0.1459, -1.5236, -1.1495],\n",
            "        [-0.8197, -0.9204, -0.4662,  ...,  0.1589, -1.4938, -1.2314]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0820, -0.0918, -0.0468,  ...,  0.0171, -0.1512, -0.1217],\n",
            "        [-0.0818, -0.0919, -0.0464,  ..., -0.0044, -0.1423, -0.1045],\n",
            "        [-0.0823, -0.0917, -0.0470,  ...,  0.0308, -0.1627, -0.1317],\n",
            "        ...,\n",
            "        [-0.0822, -0.0919, -0.0470,  ...,  0.0309, -0.1604, -0.1358],\n",
            "        [-0.0812, -0.0924, -0.0461,  ..., -0.0229, -0.1186, -0.0865],\n",
            "        [-0.0822, -0.0916, -0.0470,  ...,  0.0344, -0.1650, -0.1384]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8199, -0.9180, -0.4679,  ...,  0.1715, -1.5122, -1.2171],\n",
            "        [-0.8178, -0.9192, -0.4638,  ..., -0.0439, -1.4229, -1.0451],\n",
            "        [-0.8226, -0.9168, -0.4697,  ...,  0.3079, -1.6269, -1.3173],\n",
            "        ...,\n",
            "        [-0.8221, -0.9190, -0.4700,  ...,  0.3094, -1.6042, -1.3578],\n",
            "        [-0.8118, -0.9243, -0.4606,  ..., -0.2294, -1.1865, -0.8653],\n",
            "        [-0.8222, -0.9159, -0.4695,  ...,  0.3437, -1.6496, -1.3843]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-8.1567e-02, -9.2700e-02, -4.5853e-02,  ..., -5.7211e-06,\n",
            "         -1.2927e-01, -3.7902e-02],\n",
            "        [-8.2244e-02, -9.1591e-02, -4.6863e-02,  ...,  2.6670e-02,\n",
            "         -1.5984e-01, -1.4102e-01],\n",
            "        [-8.2581e-02, -9.1465e-02, -4.7143e-02,  ...,  4.8288e-02,\n",
            "         -1.7600e-01, -1.5246e-01],\n",
            "        ...,\n",
            "        [-8.2105e-02, -9.1716e-02, -4.6726e-02,  ...,  1.5953e-02,\n",
            "         -1.5397e-01, -1.2604e-01],\n",
            "        [-8.1836e-02, -9.1831e-02, -4.6238e-02,  ..., -3.5549e-03,\n",
            "         -1.4367e-01, -1.0367e-01],\n",
            "        [-8.2311e-02, -9.1560e-02, -4.6915e-02,  ...,  3.3510e-02,\n",
            "         -1.6496e-01, -1.3798e-01]], grad_fn=<CatBackward0>)\n",
            "New tensor([[-8.1567e-01, -9.2700e-01, -4.5853e-01,  ..., -5.7211e-05,\n",
            "         -1.2927e+00, -3.7902e-01],\n",
            "        [-8.2244e-01, -9.1591e-01, -4.6863e-01,  ...,  2.6670e-01,\n",
            "         -1.5984e+00, -1.4102e+00],\n",
            "        [-8.2581e-01, -9.1465e-01, -4.7143e-01,  ...,  4.8288e-01,\n",
            "         -1.7600e+00, -1.5246e+00],\n",
            "        ...,\n",
            "        [-8.2105e-01, -9.1716e-01, -4.6726e-01,  ...,  1.5953e-01,\n",
            "         -1.5397e+00, -1.2604e+00],\n",
            "        [-8.1836e-01, -9.1831e-01, -4.6238e-01,  ..., -3.5549e-02,\n",
            "         -1.4367e+00, -1.0367e+00],\n",
            "        [-8.2311e-01, -9.1560e-01, -4.6915e-01,  ...,  3.3510e-01,\n",
            "         -1.6496e+00, -1.3798e+00]], grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0822, -0.0917, -0.0467,  ...,  0.0158, -0.1512, -0.1169],\n",
            "        [-0.0819, -0.0919, -0.0463,  ..., -0.0063, -0.1396, -0.1028],\n",
            "        [-0.0818, -0.0920, -0.0461,  ..., -0.0202, -0.1368, -0.0864],\n",
            "        ...,\n",
            "        [-0.0825, -0.0916, -0.0469,  ...,  0.0342, -0.1628, -0.1386],\n",
            "        [-0.0819, -0.0920, -0.0463,  ..., -0.0031, -0.1370, -0.1013],\n",
            "        [-0.0824, -0.0916, -0.0467,  ...,  0.0282, -0.1616, -0.1352]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8222, -0.9167, -0.4668,  ...,  0.1582, -1.5124, -1.1687],\n",
            "        [-0.8195, -0.9186, -0.4629,  ..., -0.0631, -1.3958, -1.0281],\n",
            "        [-0.8181, -0.9198, -0.4606,  ..., -0.2023, -1.3681, -0.8640],\n",
            "        ...,\n",
            "        [-0.8247, -0.9155, -0.4690,  ...,  0.3423, -1.6285, -1.3857],\n",
            "        [-0.8186, -0.9198, -0.4631,  ..., -0.0306, -1.3703, -1.0132],\n",
            "        [-0.8242, -0.9163, -0.4674,  ...,  0.2820, -1.6161, -1.3523]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0824, -0.0915, -0.0466,  ...,  0.0186, -0.1553, -0.1280],\n",
            "        [-0.0821, -0.0918, -0.0461,  ..., -0.0049, -0.1402, -0.1015],\n",
            "        [-0.0821, -0.0919, -0.0465,  ...,  0.0165, -0.1456, -0.1249],\n",
            "        ...,\n",
            "        [-0.0821, -0.0918, -0.0462,  ..., -0.0081, -0.1367, -0.1048],\n",
            "        [-0.0830, -0.0914, -0.0469,  ...,  0.0441, -0.1792, -0.1484],\n",
            "        [-0.0824, -0.0916, -0.0464,  ...,  0.0155, -0.1559, -0.1230]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8244, -0.9154, -0.4656,  ...,  0.1860, -1.5528, -1.2805],\n",
            "        [-0.8212, -0.9177, -0.4609,  ..., -0.0491, -1.4018, -1.0148],\n",
            "        [-0.8214, -0.9195, -0.4649,  ...,  0.1648, -1.4563, -1.2491],\n",
            "        ...,\n",
            "        [-0.8206, -0.9182, -0.4616,  ..., -0.0815, -1.3671, -1.0484],\n",
            "        [-0.8300, -0.9143, -0.4689,  ...,  0.4413, -1.7916, -1.4839],\n",
            "        [-0.8242, -0.9158, -0.4642,  ...,  0.1548, -1.5588, -1.2303]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0819, -0.0919, -0.0458,  ..., -0.0300, -0.1250, -0.0919],\n",
            "        [-0.0823, -0.0916, -0.0463,  ...,  0.0121, -0.1486, -0.1078],\n",
            "        [-0.0820, -0.0919, -0.0461,  ..., -0.0019, -0.1368, -0.1023],\n",
            "        ...,\n",
            "        [-0.0818, -0.0926, -0.0456,  ...,  0.0018, -0.1273, -0.0419],\n",
            "        [-0.0820, -0.0919, -0.0461,  ..., -0.0030, -0.1347, -0.1053],\n",
            "        [-0.0818, -0.0920, -0.0458,  ..., -0.0263, -0.1221, -0.0910]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8187, -0.9190, -0.4576,  ..., -0.3001, -1.2504, -0.9186],\n",
            "        [-0.8234, -0.9155, -0.4631,  ...,  0.1206, -1.4856, -1.0776],\n",
            "        [-0.8201, -0.9194, -0.4611,  ..., -0.0189, -1.3682, -1.0230],\n",
            "        ...,\n",
            "        [-0.8182, -0.9264, -0.4558,  ...,  0.0177, -1.2730, -0.4188],\n",
            "        [-0.8202, -0.9194, -0.4613,  ..., -0.0299, -1.3468, -1.0528],\n",
            "        [-0.8175, -0.9202, -0.4580,  ..., -0.2634, -1.2207, -0.9102]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0822, -0.0919, -0.0465,  ...,  0.0160, -0.1503, -0.1098],\n",
            "        [-0.0814, -0.0922, -0.0460,  ..., -0.0200, -0.1229, -0.0892],\n",
            "        [-0.0821, -0.0918, -0.0463,  ...,  0.0007, -0.1477, -0.0999],\n",
            "        ...,\n",
            "        [-0.0820, -0.0918, -0.0463,  ..., -0.0055, -0.1396, -0.0945],\n",
            "        [-0.0823, -0.0917, -0.0466,  ...,  0.0165, -0.1527, -0.1187],\n",
            "        [-0.0815, -0.0921, -0.0459,  ..., -0.0237, -0.1275, -0.0882]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8217, -0.9186, -0.4654,  ...,  0.1597, -1.5032, -1.0982],\n",
            "        [-0.8143, -0.9221, -0.4598,  ..., -0.2000, -1.2289, -0.8917],\n",
            "        [-0.8210, -0.9178, -0.4631,  ...,  0.0066, -1.4768, -0.9993],\n",
            "        ...,\n",
            "        [-0.8195, -0.9183, -0.4631,  ..., -0.0545, -1.3962, -0.9449],\n",
            "        [-0.8226, -0.9166, -0.4661,  ...,  0.1650, -1.5274, -1.1870],\n",
            "        [-0.8153, -0.9210, -0.4594,  ..., -0.2370, -1.2745, -0.8819]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0819, -0.0919, -0.0466,  ...,  0.0141, -0.1490, -0.1098],\n",
            "        [-0.0814, -0.0921, -0.0461,  ..., -0.0200, -0.1275, -0.0854],\n",
            "        [-0.0823, -0.0916, -0.0470,  ...,  0.0341, -0.1604, -0.1371],\n",
            "        ...,\n",
            "        [-0.0822, -0.0915, -0.0468,  ...,  0.0306, -0.1626, -0.1364],\n",
            "        [-0.0816, -0.0920, -0.0464,  ..., -0.0017, -0.1334, -0.1001],\n",
            "        [-0.0820, -0.0917, -0.0467,  ...,  0.0174, -0.1513, -0.1222]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8193, -0.9187, -0.4664,  ...,  0.1409, -1.4905, -1.0983],\n",
            "        [-0.8145, -0.9209, -0.4615,  ..., -0.2001, -1.2752, -0.8543],\n",
            "        [-0.8226, -0.9156, -0.4698,  ...,  0.3414, -1.6043, -1.3712],\n",
            "        ...,\n",
            "        [-0.8223, -0.9147, -0.4682,  ...,  0.3059, -1.6263, -1.3640],\n",
            "        [-0.8163, -0.9201, -0.4640,  ..., -0.0175, -1.3338, -1.0010],\n",
            "        [-0.8204, -0.9168, -0.4665,  ...,  0.1742, -1.5131, -1.2223]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0816, -0.0919, -0.0465,  ..., -0.0020, -0.1379, -0.0992],\n",
            "        [-0.0818, -0.0917, -0.0466,  ...,  0.0172, -0.1524, -0.1131],\n",
            "        [-0.0814, -0.0922, -0.0465,  ...,  0.0029, -0.1352, -0.1020],\n",
            "        ...,\n",
            "        [-0.0818, -0.0918, -0.0468,  ...,  0.0146, -0.1473, -0.1201],\n",
            "        [-0.0813, -0.0927, -0.0459,  ...,  0.0045, -0.1294, -0.0349],\n",
            "        [-0.0811, -0.0922, -0.0462,  ..., -0.0189, -0.1194, -0.0909]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8156, -0.9195, -0.4651,  ..., -0.0200, -1.3792, -0.9919],\n",
            "        [-0.8183, -0.9165, -0.4658,  ...,  0.1720, -1.5243, -1.1310],\n",
            "        [-0.8140, -0.9221, -0.4648,  ...,  0.0290, -1.3518, -1.0205],\n",
            "        ...,\n",
            "        [-0.8179, -0.9175, -0.4677,  ...,  0.1460, -1.4733, -1.2010],\n",
            "        [-0.8129, -0.9268, -0.4586,  ...,  0.0447, -1.2941, -0.3492],\n",
            "        [-0.8108, -0.9225, -0.4618,  ..., -0.1895, -1.1937, -0.9090]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0815, -0.0918, -0.0462,  ..., -0.0105, -0.1390, -0.1018],\n",
            "        [-0.0819, -0.0916, -0.0466,  ...,  0.0189, -0.1567, -0.1211],\n",
            "        [-0.0818, -0.0917, -0.0466,  ...,  0.0144, -0.1489, -0.1150],\n",
            "        ...,\n",
            "        [-0.0820, -0.0916, -0.0467,  ...,  0.0151, -0.1557, -0.1174],\n",
            "        [-0.0818, -0.0919, -0.0466,  ...,  0.0137, -0.1486, -0.1127],\n",
            "        [-0.0817, -0.0918, -0.0464,  ..., -0.0029, -0.1428, -0.1049]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8153, -0.9181, -0.4616,  ..., -0.1052, -1.3904, -1.0179],\n",
            "        [-0.8195, -0.9160, -0.4664,  ...,  0.1889, -1.5668, -1.2114],\n",
            "        [-0.8181, -0.9172, -0.4661,  ...,  0.1436, -1.4889, -1.1497],\n",
            "        ...,\n",
            "        [-0.8196, -0.9160, -0.4668,  ...,  0.1512, -1.5571, -1.1740],\n",
            "        [-0.8178, -0.9187, -0.4656,  ...,  0.1374, -1.4863, -1.1268],\n",
            "        [-0.8169, -0.9177, -0.4638,  ..., -0.0285, -1.4281, -1.0487]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0817, -0.0918, -0.0463,  ...,  0.0002, -0.1369, -0.0994],\n",
            "        [-0.0824, -0.0914, -0.0470,  ...,  0.0510, -0.1693, -0.1379],\n",
            "        [-0.0820, -0.0916, -0.0465,  ...,  0.0118, -0.1490, -0.1133],\n",
            "        ...,\n",
            "        [-0.0820, -0.0916, -0.0465,  ...,  0.0139, -0.1522, -0.1175],\n",
            "        [-0.0816, -0.0920, -0.0463,  ..., -0.0027, -0.1344, -0.1027],\n",
            "        [-0.0819, -0.0918, -0.0465,  ...,  0.0185, -0.1482, -0.1116]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.8167, -0.9178, -0.4629,  ...,  0.0020, -1.3694, -0.9939],\n",
            "        [-0.8236, -0.9142, -0.4701,  ...,  0.5102, -1.6934, -1.3789],\n",
            "        [-0.8196, -0.9157, -0.4648,  ...,  0.1176, -1.4901, -1.1332],\n",
            "        ...,\n",
            "        [-0.8202, -0.9158, -0.4650,  ...,  0.1393, -1.5216, -1.1748],\n",
            "        [-0.8157, -0.9195, -0.4626,  ..., -0.0273, -1.3441, -1.0274],\n",
            "        [-0.8192, -0.9184, -0.4654,  ...,  0.1851, -1.4817, -1.1156]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Training loss 0.004794892854988575\n",
            "Old tensor([[-0.0815, -0.0925, -0.0457,  ...,  0.0062, -0.1312, -0.0410],\n",
            "        [-0.0821, -0.0914, -0.0466,  ...,  0.0163, -0.1513, -0.1185],\n",
            "        [-0.0821, -0.0914, -0.0463,  ...,  0.0173, -0.1531, -0.1175],\n",
            "        ...,\n",
            "        [-0.0816, -0.0925, -0.0457,  ...,  0.0042, -0.1317, -0.0340],\n",
            "        [-0.0816, -0.0924, -0.0457,  ...,  0.0019, -0.1314, -0.0391],\n",
            "        [-0.0821, -0.0915, -0.0463,  ...,  0.0125, -0.1509, -0.1181]])\n",
            "New tensor([[-0.8153, -0.9254, -0.4566,  ...,  0.0617, -1.3123, -0.4095],\n",
            "        [-0.8211, -0.9145, -0.4657,  ...,  0.1626, -1.5134, -1.1846],\n",
            "        [-0.8206, -0.9139, -0.4630,  ...,  0.1728, -1.5314, -1.1750],\n",
            "        ...,\n",
            "        [-0.8161, -0.9246, -0.4566,  ...,  0.0420, -1.3166, -0.3400],\n",
            "        [-0.8158, -0.9239, -0.4565,  ...,  0.0191, -1.3141, -0.3906],\n",
            "        [-0.8208, -0.9153, -0.4629,  ...,  0.1250, -1.5088, -1.1806]])\n",
            "Old tensor([[-0.0812, -0.0921, -0.0459,  ..., -0.0194, -0.1193, -0.0886],\n",
            "        [-0.0815, -0.0921, -0.0462,  ...,  0.0028, -0.1322, -0.1030],\n",
            "        [-0.0825, -0.0912, -0.0469,  ...,  0.0489, -0.1707, -0.1389],\n",
            "        ...,\n",
            "        [-0.0821, -0.0914, -0.0465,  ...,  0.0113, -0.1495, -0.1202],\n",
            "        [-0.0819, -0.0916, -0.0462,  ..., -0.0034, -0.1424, -0.0970],\n",
            "        [-0.0815, -0.0926, -0.0457,  ...,  0.0064, -0.1280, -0.0387]])\n",
            "New tensor([[-0.8124, -0.9214, -0.4586,  ..., -0.1943, -1.1927, -0.8864],\n",
            "        [-0.8153, -0.9208, -0.4622,  ...,  0.0280, -1.3217, -1.0297],\n",
            "        [-0.8251, -0.9125, -0.4695,  ...,  0.4886, -1.7066, -1.3895],\n",
            "        ...,\n",
            "        [-0.8205, -0.9145, -0.4645,  ...,  0.1132, -1.4949, -1.2025],\n",
            "        [-0.8185, -0.9162, -0.4621,  ..., -0.0338, -1.4237, -0.9696],\n",
            "        [-0.8145, -0.9260, -0.4570,  ...,  0.0636, -1.2796, -0.3866]])\n",
            "Old tensor([[-0.0819, -0.0916, -0.0462,  ..., -0.0028, -0.1399, -0.0956],\n",
            "        [-0.0824, -0.0913, -0.0467,  ...,  0.0314, -0.1654, -0.1346],\n",
            "        [-0.0824, -0.0913, -0.0468,  ...,  0.0338, -0.1622, -0.1365],\n",
            "        ...,\n",
            "        [-0.0820, -0.0916, -0.0464,  ...,  0.0148, -0.1468, -0.1138],\n",
            "        [-0.0823, -0.0913, -0.0468,  ...,  0.0351, -0.1615, -0.1361],\n",
            "        [-0.0817, -0.0917, -0.0462,  ...,  0.0007, -0.1353, -0.1094]])\n",
            "New tensor([[-0.8190, -0.9160, -0.4617,  ..., -0.0281, -1.3990, -0.9558],\n",
            "        [-0.8239, -0.9131, -0.4670,  ...,  0.3140, -1.6543, -1.3462],\n",
            "        [-0.8235, -0.9125, -0.4677,  ...,  0.3376, -1.6221, -1.3652],\n",
            "        ...,\n",
            "        [-0.8197, -0.9164, -0.4644,  ...,  0.1476, -1.4679, -1.1375],\n",
            "        [-0.8231, -0.9128, -0.4680,  ...,  0.3515, -1.6152, -1.3606],\n",
            "        [-0.8166, -0.9175, -0.4617,  ...,  0.0074, -1.3528, -1.0943]])\n",
            "Old tensor([[-0.0818, -0.0916, -0.0462,  ..., -0.0010, -0.1378, -0.1037],\n",
            "        [-0.0812, -0.0922, -0.0459,  ..., -0.0195, -0.1183, -0.0885],\n",
            "        [-0.0824, -0.0913, -0.0468,  ...,  0.0336, -0.1647, -0.1333],\n",
            "        ...,\n",
            "        [-0.0815, -0.0919, -0.0459,  ..., -0.0202, -0.1281, -0.0852],\n",
            "        [-0.0815, -0.0926, -0.0456,  ...,  0.0067, -0.1306, -0.0351],\n",
            "        [-0.0818, -0.0923, -0.0459,  ...,  0.0236, -0.1416, -0.0484]])\n",
            "New tensor([[-0.8179, -0.9163, -0.4620,  ..., -0.0098, -1.3783, -1.0371],\n",
            "        [-0.8121, -0.9216, -0.4588,  ..., -0.1946, -1.1831, -0.8852],\n",
            "        [-0.8238, -0.9127, -0.4676,  ...,  0.3362, -1.6472, -1.3330],\n",
            "        ...,\n",
            "        [-0.8152, -0.9189, -0.4595,  ..., -0.2025, -1.2814, -0.8523],\n",
            "        [-0.8155, -0.9261, -0.4563,  ...,  0.0669, -1.3057, -0.3507],\n",
            "        [-0.8182, -0.9228, -0.4595,  ...,  0.2363, -1.4159, -0.4840]])\n",
            "Old tensor([[-0.0820, -0.0916, -0.0462,  ..., -0.0033, -0.1458, -0.1080],\n",
            "        [-0.0818, -0.0917, -0.0461,  ..., -0.0038, -0.1414, -0.0977],\n",
            "        [-0.0821, -0.0914, -0.0464,  ...,  0.0175, -0.1529, -0.1176],\n",
            "        ...,\n",
            "        [-0.0818, -0.0916, -0.0460,  ..., -0.0033, -0.1407, -0.0966],\n",
            "        [-0.0817, -0.0922, -0.0459,  ...,  0.0175, -0.1383, -0.0583],\n",
            "        [-0.0824, -0.0911, -0.0470,  ...,  0.0528, -0.1702, -0.1577]])\n",
            "New tensor([[-0.8198, -0.9156, -0.4618,  ..., -0.0333, -1.4583, -1.0802],\n",
            "        [-0.8184, -0.9165, -0.4612,  ..., -0.0383, -1.4138, -0.9772],\n",
            "        [-0.8208, -0.9144, -0.4637,  ...,  0.1751, -1.5286, -1.1757],\n",
            "        ...,\n",
            "        [-0.8176, -0.9156, -0.4605,  ..., -0.0332, -1.4075, -0.9663],\n",
            "        [-0.8171, -0.9217, -0.4585,  ...,  0.1751, -1.3832, -0.5835],\n",
            "        [-0.8244, -0.9112, -0.4701,  ...,  0.5276, -1.7020, -1.5773]])\n",
            "Old tensor([[-0.0820, -0.0915, -0.0464,  ...,  0.0144, -0.1490, -0.1236],\n",
            "        [-0.0826, -0.0911, -0.0470,  ...,  0.0506, -0.1728, -0.1493],\n",
            "        [-0.0822, -0.0913, -0.0467,  ...,  0.0346, -0.1600, -0.1388],\n",
            "        ...,\n",
            "        [-0.0824, -0.0913, -0.0467,  ...,  0.0341, -0.1637, -0.1333],\n",
            "        [-0.0820, -0.0916, -0.0466,  ...,  0.0224, -0.1513, -0.1208],\n",
            "        [-0.0815, -0.0921, -0.0461,  ..., -0.0048, -0.1336, -0.0986]])\n",
            "New tensor([[-0.8203, -0.9155, -0.4643,  ...,  0.1440, -1.4898, -1.2357],\n",
            "        [-0.8258, -0.9113, -0.4702,  ...,  0.5062, -1.7280, -1.4926],\n",
            "        [-0.8224, -0.9133, -0.4668,  ...,  0.3459, -1.5999, -1.3876],\n",
            "        ...,\n",
            "        [-0.8236, -0.9133, -0.4672,  ...,  0.3410, -1.6369, -1.3327],\n",
            "        [-0.8205, -0.9157, -0.4657,  ...,  0.2241, -1.5130, -1.2085],\n",
            "        [-0.8151, -0.9213, -0.4606,  ..., -0.0479, -1.3357, -0.9856]])\n",
            "Old tensor([[-8.1675e-02, -9.1861e-02, -4.6154e-02,  ..., -1.0467e-03,\n",
            "         -1.3814e-01, -1.0454e-01],\n",
            "        [-8.2001e-02, -9.1636e-02, -4.6474e-02,  ...,  1.5910e-02,\n",
            "         -1.4906e-01, -1.1983e-01],\n",
            "        [-8.1815e-02, -9.1613e-02, -4.6104e-02,  ...,  4.3456e-06,\n",
            "         -1.4129e-01, -1.0800e-01],\n",
            "        ...,\n",
            "        [-8.1825e-02, -9.2382e-02, -4.5928e-02,  ...,  2.3682e-02,\n",
            "         -1.4529e-01, -4.0449e-02],\n",
            "        [-8.1916e-02, -9.1690e-02, -4.6399e-02,  ...,  1.8971e-02,\n",
            "         -1.4863e-01, -1.1291e-01],\n",
            "        [-8.1669e-02, -9.2393e-02, -4.5695e-02,  ...,  5.1043e-03,\n",
            "         -1.3627e-01, -3.7498e-02]])\n",
            "New tensor([[-8.1675e-01, -9.1861e-01, -4.6154e-01,  ..., -1.0467e-02,\n",
            "         -1.3814e+00, -1.0454e+00],\n",
            "        [-8.2001e-01, -9.1636e-01, -4.6474e-01,  ...,  1.5910e-01,\n",
            "         -1.4906e+00, -1.1983e+00],\n",
            "        [-8.1815e-01, -9.1613e-01, -4.6104e-01,  ...,  4.3456e-05,\n",
            "         -1.4129e+00, -1.0800e+00],\n",
            "        ...,\n",
            "        [-8.1825e-01, -9.2382e-01, -4.5928e-01,  ...,  2.3682e-01,\n",
            "         -1.4529e+00, -4.0449e-01],\n",
            "        [-8.1916e-01, -9.1690e-01, -4.6399e-01,  ...,  1.8971e-01,\n",
            "         -1.4863e+00, -1.1291e+00],\n",
            "        [-8.1669e-01, -9.2393e-01, -4.5695e-01,  ...,  5.1043e-02,\n",
            "         -1.3627e+00, -3.7498e-01]])\n",
            "Old tensor([[-0.0815, -0.0923, -0.0457,  ...,  0.0011, -0.1288, -0.0472],\n",
            "        [-0.0816, -0.0917, -0.0457,  ..., -0.0257, -0.1342, -0.0895],\n",
            "        [-0.0821, -0.0914, -0.0463,  ...,  0.0164, -0.1542, -0.1168],\n",
            "        ...,\n",
            "        [-0.0818, -0.0918, -0.0461,  ..., -0.0035, -0.1388, -0.0964],\n",
            "        [-0.0820, -0.0916, -0.0465,  ...,  0.0174, -0.1476, -0.1136],\n",
            "        [-0.0822, -0.0913, -0.0466,  ...,  0.0237, -0.1559, -0.1279]])\n",
            "New tensor([[-0.8153, -0.9229, -0.4569,  ...,  0.0112, -1.2876, -0.4718],\n",
            "        [-0.8159, -0.9173, -0.4573,  ..., -0.2566, -1.3424, -0.8946],\n",
            "        [-0.8212, -0.9145, -0.4632,  ...,  0.1639, -1.5417, -1.1677],\n",
            "        ...,\n",
            "        [-0.8178, -0.9179, -0.4610,  ..., -0.0354, -1.3878, -0.9639],\n",
            "        [-0.8196, -0.9162, -0.4646,  ...,  0.1739, -1.4760, -1.1357],\n",
            "        [-0.8217, -0.9135, -0.4664,  ...,  0.2374, -1.5587, -1.2793]])\n",
            "Old tensor([[-0.0819, -0.0916, -0.0462,  ..., -0.0044, -0.1431, -0.0977],\n",
            "        [-0.0817, -0.0919, -0.0462,  ..., -0.0032, -0.1365, -0.1011],\n",
            "        [-0.0815, -0.0925, -0.0455,  ...,  0.0034, -0.1307, -0.0299],\n",
            "        ...,\n",
            "        [-0.0821, -0.0913, -0.0464,  ...,  0.0206, -0.1582, -0.1208],\n",
            "        [-0.0816, -0.0917, -0.0459,  ..., -0.0261, -0.1299, -0.0867],\n",
            "        [-0.0818, -0.0916, -0.0461,  ..., -0.0084, -0.1392, -0.1024]])\n",
            "New tensor([[-0.8188, -0.9165, -0.4617,  ..., -0.0438, -1.4311, -0.9769],\n",
            "        [-0.8168, -0.9189, -0.4619,  ..., -0.0317, -1.3652, -1.0113],\n",
            "        [-0.8153, -0.9249, -0.4548,  ...,  0.0343, -1.3071, -0.2994],\n",
            "        ...,\n",
            "        [-0.8211, -0.9131, -0.4637,  ...,  0.2057, -1.5823, -1.2078],\n",
            "        [-0.8160, -0.9172, -0.4590,  ..., -0.2607, -1.2987, -0.8673],\n",
            "        [-0.8182, -0.9161, -0.4611,  ..., -0.0843, -1.3922, -1.0242]])\n",
            "Old tensor([[-0.0818, -0.0917, -0.0462,  ..., -0.0012, -0.1391, -0.1048],\n",
            "        [-0.0821, -0.0914, -0.0465,  ...,  0.0125, -0.1516, -0.1232],\n",
            "        [-0.0822, -0.0914, -0.0465,  ...,  0.0147, -0.1544, -0.1211],\n",
            "        ...,\n",
            "        [-0.0821, -0.0916, -0.0464,  ...,  0.0151, -0.1506, -0.1081],\n",
            "        [-0.0817, -0.0918, -0.0462,  ..., -0.0026, -0.1334, -0.1062],\n",
            "        [-0.0819, -0.0917, -0.0462,  ..., -0.0016, -0.1424, -0.0963]])\n",
            "New tensor([[-0.8179, -0.9174, -0.4623,  ..., -0.0122, -1.3908, -1.0478],\n",
            "        [-0.8210, -0.9138, -0.4647,  ...,  0.1246, -1.5158, -1.2320],\n",
            "        [-0.8216, -0.9138, -0.4654,  ...,  0.1466, -1.5442, -1.2113],\n",
            "        ...,\n",
            "        [-0.8206, -0.9155, -0.4641,  ...,  0.1506, -1.5065, -1.0808],\n",
            "        [-0.8166, -0.9178, -0.4621,  ..., -0.0262, -1.3335, -1.0623],\n",
            "        [-0.8192, -0.9169, -0.4624,  ..., -0.0157, -1.4241, -0.9634]])\n",
            "Old tensor([[-0.0815, -0.0921, -0.0462,  ..., -0.0025, -0.1312, -0.1039],\n",
            "        [-0.0823, -0.0913, -0.0466,  ...,  0.0294, -0.1626, -0.1355],\n",
            "        [-0.0822, -0.0915, -0.0466,  ...,  0.0317, -0.1626, -0.1269],\n",
            "        ...,\n",
            "        [-0.0816, -0.0923, -0.0456,  ..., -0.0005, -0.1315, -0.0406],\n",
            "        [-0.0824, -0.0913, -0.0466,  ...,  0.0296, -0.1648, -0.1317],\n",
            "        [-0.0813, -0.0921, -0.0459,  ..., -0.0188, -0.1202, -0.0883]])\n",
            "New tensor([[-0.8150, -0.9206, -0.4615,  ..., -0.0247, -1.3123, -1.0389],\n",
            "        [-0.8231, -0.9126, -0.4662,  ...,  0.2944, -1.6256, -1.3553],\n",
            "        [-0.8225, -0.9152, -0.4657,  ...,  0.3168, -1.6264, -1.2686],\n",
            "        ...,\n",
            "        [-0.8157, -0.9226, -0.4562,  ..., -0.0052, -1.3145, -0.4055],\n",
            "        [-0.8237, -0.9135, -0.4660,  ...,  0.2957, -1.6485, -1.3167],\n",
            "        [-0.8135, -0.9206, -0.4594,  ..., -0.1875, -1.2023, -0.8833]])\n",
            "Validation loss 0.002414839109405875\n"
          ]
        }
      ]
    }
  ]
}