{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williamtbarker/ML4Molecules/blob/main/09_Hyperparameter_Tuning_complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimal hyperparameters\n",
        "\n",
        "The model weights are the parameters for the ML model. However, the model arguments (example: number of hidden layers, type of kernel etc) also play a role in determining the model parameters. Hence, these model arguments are called hyperparameters.\n",
        "\n",
        "One should optimize these hyperparameters too. Here, we will look at one such example using the QM9 dataset and SVR model"
      ],
      "metadata": {
        "id": "JcHdbe0-VlC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install rdkit and deepchem\n",
        "! pip install rdkit\n",
        "! pip install deepchem\n",
        "\n",
        "# install Fast-ML\n",
        "! pip install fast_ml"
      ],
      "metadata": {
        "id": "rQgrtqPGVDiR",
        "outputId": "952a9da1-762d-42b1-b3e4-aeb45ee2b3fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.4\n",
            "Collecting deepchem\n",
            "  Downloading deepchem-2.7.1-py3-none-any.whl (693 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.2/693.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.2)\n",
            "Collecting scipy<1.9 (from deepchem)\n",
            "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (from deepchem) (2023.9.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2023.3.post1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (9.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->deepchem) (1.16.0)\n",
            "Installing collected packages: scipy, deepchem\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "jax 0.4.23 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "jaxlib 0.4.23+cuda12.cudnn89 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deepchem-2.7.1 scipy-1.8.1\n",
            "Collecting fast_ml\n",
            "  Downloading fast_ml-3.68-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fast_ml\n",
            "Successfully installed fast_ml-3.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import that pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# load the dataframe as CSV from URL.\n",
        "df = pd.read_csv(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\")\n",
        "\n",
        "# we will use 5 % of the dataset for demo\n",
        "dataset = df[[\"smiles\",\"gap\"]].sample(frac=0.05)\n",
        "\n",
        "# import depechem and rdkit\n",
        "import deepchem as dc\n",
        "from rdkit import Chem\n",
        "\n",
        "# create the featurizer object\n",
        "# we will set the radius=2, size=100 as before\n",
        "featurizer = dc.feat.CircularFingerprint(size=100, radius=2)\n",
        "\n",
        "# apply to the dataset\n",
        "dataset[\"fp\"] = dataset[\"smiles\"].apply(featurizer.featurize)\n",
        "\n",
        "# the fp is an multi-dimensional array but we want to list for training\n",
        "dataset[\"fp\"] = dataset[\"fp\"].apply(lambda x: list(x[0]))\n",
        "\n",
        "\n",
        "# import the function to split into train-valid-test\n",
        "from fast_ml.model_development import train_valid_test_split\n",
        "\n",
        "# we will split the dataset as train-valid-test = 0.8:0.1:0.1\n",
        "X_train, y_train, X_valid, y_valid, \\\n",
        "X_test, y_test = train_valid_test_split(dataset[[\"fp\",\"gap\"]], target = \"gap\", train_size=0.8,\n",
        "                                        valid_size=0.1, test_size=0.1)"
      ],
      "metadata": {
        "id": "g1rkOpTLVBKc",
        "outputId": "c205f009-ed8e-4848-91e8-bb51364242a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.10/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning\n",
        "\n",
        "There are python packages that do this. Here, we use [optuna](https://optuna.org/)"
      ],
      "metadata": {
        "id": "fzSR_abwWnn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install optuna\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "GvKmARLiW9hi",
        "outputId": "39712c5f-b5c1-4e5f-9d37-91ab65896ab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.1 colorlog-6.8.0 optuna-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code has an objective function which can be minimized or maximized. Here, we will try to maximize the R<sup>2</sup> score. Below is the pseudo code\n",
        "\n",
        "########################\n",
        "\n",
        "1. import the libraries\n",
        "\n",
        "2. define objective function - this should involve train the model with the choose hyperparameters\n",
        "\n",
        "3. create the study object\n",
        "4. optimize\n",
        "\n"
      ],
      "metadata": {
        "id": "eUvXcCeBXJeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the model class and optuna\n",
        "from sklearn.svm import SVR\n",
        "import optuna\n",
        "\n",
        "#create objective (essentially training)\n",
        "def objective(trial):\n",
        "  # we will have kernel, and C as the hyperparameters\n",
        "  kernel = trial.suggest_categorical(\"kernel\",[\"rbf\",\"linear\",\"poly\",\"sigmoid\"])\n",
        "  C = trial.suggest_float(\"C\",0.1,1)\n",
        "\n",
        "  # create the model and fit\n",
        "  svr = SVR(kernel=kernel, C=C)\n",
        "  model = svr.fit(X_train[\"fp\"].values.tolist(),y_train.values.tolist())\n",
        "\n",
        "  # compute the score on valid dataset\n",
        "  score = model.score(X_valid[\"fp\"].values.tolist(),y_valid.values.tolist())\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "n1knBFSqVFnB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start optimization"
      ],
      "metadata": {
        "id": "5qLbFp-ApRXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the study object\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# run optimization\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "id": "c9MpqDt4VPlr",
        "outputId": "4e9e2009-be43-404d-e5af-21a6d4a7880d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-09 17:22:55,895] A new study created in memory with name: no-name-8532b5de-eb30-4159-89fc-6f2382e1fa8d\n",
            "[I 2024-01-09 17:22:55,979] Trial 0 finished with value: 0.17453615647587895 and parameters: {'kernel': 'poly', 'C': 0.2354012397479017}. Best is trial 0 with value: 0.17453615647587895.\n",
            "[I 2024-01-09 17:23:00,531] Trial 1 finished with value: -297.5149984579547 and parameters: {'kernel': 'sigmoid', 'C': 0.2963463332250755}. Best is trial 0 with value: 0.17453615647587895.\n",
            "[I 2024-01-09 17:23:04,943] Trial 2 finished with value: -3088.154417039526 and parameters: {'kernel': 'sigmoid', 'C': 0.9508891707312666}. Best is trial 0 with value: 0.17453615647587895.\n",
            "[I 2024-01-09 17:23:04,998] Trial 3 finished with value: 0.2410063671033833 and parameters: {'kernel': 'rbf', 'C': 0.927505709341099}. Best is trial 3 with value: 0.2410063671033833.\n",
            "[I 2024-01-09 17:23:05,142] Trial 4 finished with value: 0.4099380073024903 and parameters: {'kernel': 'sigmoid', 'C': 0.19682713707536031}. Best is trial 4 with value: 0.4099380073024903.\n",
            "[I 2024-01-09 17:23:08,663] Trial 5 finished with value: -1502.1723796176002 and parameters: {'kernel': 'sigmoid', 'C': 0.6609443689955465}. Best is trial 4 with value: 0.4099380073024903.\n",
            "[I 2024-01-09 17:23:08,724] Trial 6 finished with value: 0.17561318013933547 and parameters: {'kernel': 'poly', 'C': 0.2814190234583295}. Best is trial 4 with value: 0.4099380073024903.\n",
            "[I 2024-01-09 17:23:08,772] Trial 7 finished with value: 0.2410063671033833 and parameters: {'kernel': 'rbf', 'C': 0.9105176324348971}. Best is trial 4 with value: 0.4099380073024903.\n",
            "[I 2024-01-09 17:23:12,394] Trial 8 finished with value: -1909.3310009987283 and parameters: {'kernel': 'sigmoid', 'C': 0.742602514321253}. Best is trial 4 with value: 0.4099380073024903.\n",
            "[I 2024-01-09 17:23:12,469] Trial 9 finished with value: 0.3603524196469208 and parameters: {'kernel': 'linear', 'C': 0.9820110570916405}. Best is trial 4 with value: 0.4099380073024903.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the best model hyperparameters"
      ],
      "metadata": {
        "id": "-lot0wglq_BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_value"
      ],
      "metadata": {
        "id": "NSF4FxkJrFjr",
        "outputId": "ccb8f162-9399-4b9b-e6ff-877b8eb0f5bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4099380073024903"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_trial.params"
      ],
      "metadata": {
        "id": "IFcKf6DqrCwd",
        "outputId": "55fb39ab-473a-40ed-b4e9-f60df979f2d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kernel': 'sigmoid', 'C': 0.19682713707536031}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}